{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660b48f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AAPL data range: 2020-01-02 00:00:00 to 2023-12-28 00:00:00\n",
      "Total AAPL rows: 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:38:11,043] A new study created in RDB with name: a2c_hyperparam_tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1166424.78\n",
      "total_reward: 166424.78\n",
      "total_cost: 5717.30\n",
      "total_trades: 729\n",
      "Sharpe: 0.335\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:38:17,352] Trial 0 finished with value: 13.362418366639673 and parameters: {'learning_rate': 0.00017862234745427143, 'n_steps': 50, 'gamma': 0.9399658260932027, 'ent_coef': 0.007106783234186186}. Best is trial 0 with value: 13.362418366639673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.00977536711501889\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.025720364456181415\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08798758419875521\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013629059136961587\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014884192126465497\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0869878149078344\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0029436951477080585\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.020483221966552084\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022896601885987914\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008620963745121845\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00025150829162448645\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04563541717529297\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.077522042962641\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.037753513790888246\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02304462882690132\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08878225738524925\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08513999672698556\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1261432231750456\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06684617233276367\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05689964584198315\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.32261872116088636\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25608614776611793\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21293609585571105\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20824389518738026\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18547711161040933\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08297579208373791\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.028033517947385556\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22342179443358912\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05916998367309571\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2068871189086931\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16911530647735346\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1258827147949254\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4511190989563009\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05040093734741677\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.062477282714843756\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3791456649780274\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17902338175048355\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07466469575500814\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3274380163574242\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09203194554900984\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7866577629257226\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.41357863443603277\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3152860989624052\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17556264748534886\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.31414319578857397\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2744298043670599\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23779309136962984\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24348107354126405\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04589411419067765\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35534859176635514\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11600868957519997\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31940926004791403\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2657060526123038\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21126694807892202\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16565292109680596\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21142335479736796\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3389380422973656\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11545094364166726\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5867671684616129\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31122352878417586\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5206462113265996\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2611675339080859\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.115384357913211\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4161660919189453\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20067179299315904\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5627817851257277\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25779059216919126\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15481584960937034\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1396306188964869\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07381201119842008\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.003025573101802729\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.28145278305053945\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2561625460907002\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2275437446289114\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3728038973754854\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06613966766357189\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3580877810668899\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.004006828002934344\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.096574155082705\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2950461772460956\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.022660942436219193\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2536301706314087\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25385123260498516\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3802229117340059\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7744898093841506\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01762571236267686\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.42523398910521065\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4541997479248094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04480343063354958\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24146089324951173\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1242807185363723\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0017036428833031097\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16255333343505626\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.600200668182387\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02752083937530406\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25067764799194414\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6942229535354767\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07408335845031543\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3172320790100028\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6930468013046309\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5488950881958008\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.015733914062473923\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8401156945800642\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25573361422119195\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.40291152725676077\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10911199432527648\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.42481519775390625\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8079755477905274\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11195662715760991\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8452396908569383\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14754573699799367\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.19981790847778322\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6372149434219347\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3503131176757626\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.026945495004253462\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.32631288969116284\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9113693035888719\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09883797345582862\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.44389795157164336\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8854495755188168\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.38788400176998694\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11283736877443735\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4828897680847208\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.49851437102661006\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.38477623397829014\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15598886688232888\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.384759355010977\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7011422218719497\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18591494458005764\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5897080240707147\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27380589775543196\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.053262325592036364\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2328464380981634\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1017266802978702\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5371726229751483\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7903304092467995\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4784958907867549\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3295589709320106\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35711450689542107\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.36854991271973125\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.536170605163579\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0859247638336382\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2622800581360003\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3532465397674823\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3009168879699662\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6109849827453727\n",
      "Current state shape: (13,)\n",
      "Step reward: -4.065593490905734\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3606762350464008\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4024042190643493\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7020352087402484\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0996441204834031\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02663729313965887\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7600322525024414\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9078188513946603\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.39882111156616595\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.185963799580373\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22897852478027345\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6406365475448548\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6622883539306699\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8910836158752442\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.3347341382934594\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1068796924560447\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7870077941894532\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9913603568084772\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8000689160919283\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11252982879637276\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.833069763847394\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1235659939300269\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.4593234558105936\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.745575051962235\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31736421967620265\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6143063052368234\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5985375079147401\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0819063877380337\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7788434945129324\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3801214462646516\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5406198900756893\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5599834892272949\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.846490645468142\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8092378328689607\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4475410293197725\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6649795069091721\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.102221408279415\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7824983047668473\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13375438003387535\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.26370435699463124\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2963712829589844\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.686688697052002\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6513759658813477\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6585711154174758\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.335515802612307\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7679954437316978\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3130795836166479\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7449914176940918\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.48462907140199096\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.012141072692885\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07358958361968398\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8651645613403293\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7200056914031971\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20789497380829416\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3967674665969798\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.062039816589350816\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.234246942260745\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2725693852233935\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.3299002113342286\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7357476699707098\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1229547241210938\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2564042294006329\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.683571691436763\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.919014954589843\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4852760795959505\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.358408791740425\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.367340971000679\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5634961413696641\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25945240280160214\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.313657589721726\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8922993034149288\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4816628136444139\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3238854942321778\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9738419163436862\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013549177551292814\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0282986721496796\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.471904464221187\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3860359101410257\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7625235717087053\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10483147320556455\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35470748597106433\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.602051953125\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3323040941406507\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7522720100692474\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0578113296508789\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.2903669842529344\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6375961825073231\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1253836195434443\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8392860366897891\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.4781717895965791\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.893858009338379\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8645187077331358\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08269909820556641\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3102523670196533\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9459452847289853\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5776235784912249\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1875357711792458\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08599497634884902\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6248391868591309\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3195085502502043\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0563971275329357\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24830511212765707\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24830511212765707\n",
      "Current state shape: (13,)\n",
      "Total test reward: 13.362418366639673\n",
      "[I 2025-07-03 14:38:17.333013] Trial 0 finished with value: 13.362418366639673 and parameters: {'learning_rate': 0.00017862234745427143, 'n_steps': 50, 'gamma': 0.9399658260932027, 'ent_coef': 0.007106783234186186}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1004374.16\n",
      "total_reward: 4374.16\n",
      "total_cost: 4875.69\n",
      "total_trades: 613\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:38:23,482] Trial 1 finished with value: -0.24403100076607676 and parameters: {'learning_rate': 0.0011161586948051385, 'n_steps': 50, 'gamma': 0.915928229632848, 'ent_coef': 0.006361647962285382}. Best is trial 0 with value: 13.362418366639673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step reward: 0.00239797738037305\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0006969143463182264\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.002107319183344953\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01171604326934321\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.020687141113285908\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00775613830566872\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0002075636184657924\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03448289155578241\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010473782043461688\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0027209435791010037\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.004116313879389781\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0007702524414053187\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.017666360977175645\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05871277923583985\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011209737098694314\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001410203608707525\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02887097625732422\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001497896881098859\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0004337775573716499\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01837751206054818\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001034378509526141\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012524722549435683\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004058972625737079\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007883075927733444\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.021956355285644533\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011169239135691896\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006504933166503906\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02698484978027409\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0058247945190407335\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0005822557067847811\n",
      "Current state shape: (13,)\n",
      "Step reward: -5.973051757318899e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013198886059573853\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014993644665530884\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02675174063110026\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0193981951324502\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02368268740234198\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04526983758850256\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010164490959164687\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04882119308471447\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.024905119018559345\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04070636154174572\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014553762255853508\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.023467397262575105\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00453006820678711\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0008799681884818711\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005054907495121006\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00037558685302501544\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018452397669979838\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005403362170408946\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005939554061857053\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0015297123840311542\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006682322746282444\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.029172830383304975\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0030971421813941564\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014334440390008968\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014946480804448948\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.016469530029292218\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0693888621459948\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0027095967102097347\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0013746057128882967\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0021669798278831877\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005102355636539869\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001666707650758326\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08496081097564893\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02698246022796957\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0022082599868765104\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012171837997436524\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.023651733093266375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03637308249511989\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09066793121338124\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0014243811462423765\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01738040514526656\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.017149986065668053\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0016645406326279044\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0003236921478295699\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0003236921478295699\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0053946892822277735\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007907940397644416\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0004925919219967909\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005714178538508714\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.002870069403073285\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010159528442379087\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0015074460540781729\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01653851271972526\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012010534362797627\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.010201334075932392\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011023588836658747\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0002280948089552112\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00019708275146549569\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0005878263931255788\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00023676446380559355\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.8798162846360357e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012435333404538687\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001219392700190656\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.7029254145454614e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.001289463104249444\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007235471737675835\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.003169572448730469\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.094395272979734\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04111757979431423\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04148888908233494\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014260656616208144\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03163907159423689\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07894793182372814\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.024923783074948008\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0565342097473098\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.023850630265811926\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0013811274719191715\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04250359337616246\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0031288894744822757\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001572838351444807\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00849032735901419\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006012510917661712\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0015076303054811435\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014598753662104719\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.032780386654660106\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012119230499269907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014585477615357377\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.035351625592040366\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.021766417285159698\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12033468340759865\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011750150146486704\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005666466308641248\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0147945068359375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0017792097473167815\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.027230141143803486\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.003080525680538267\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011635325756832026\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.024301858062739486\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10712324805450626\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18131048645019765\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06608525342406939\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06166990661621094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.19311717604064615\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17167297661590855\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006667063293454703\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07498188923340059\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01164231012420496\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.37814578967285345\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.30196606517639013\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.027066209869389422\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0568551297607366\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1283589798431378\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06784682601928944\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04331913388061803\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.029895799713139423\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08307531402588357\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025182187271118164\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10048014863891294\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04208768128966913\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.028479808412166314\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05581896987914806\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1783347238311777\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.061694557940668894\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010005139772035182\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02377509063720936\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10423967376708752\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.058346021080017095\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.040014283752441406\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04992917138672201\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07858274597168202\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05980778686522972\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02308237685088534\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03695332412719727\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0318680599823012\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05194948791504139\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0038980789688066583\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.030423284277343192\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03284463651580736\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008357571464544163\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06124791399536189\n",
      "Current state shape: (13,)\n",
      "Step reward: -8.383758545387537e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0079346623168909\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.027470590667729267\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.053714352058409714\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02644922663574107\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03575744281006046\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00822985649871407\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.021783901519770735\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005458543212886434\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00031688486938364805\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004490782369999215\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005647233982849866\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012207847290043719\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005921436523436569\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0020819778442382813\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025266559753415643\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.018026610076904762\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00995213488006266\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.010279837799072267\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011397081146249548\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007138746185298078\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006900440826418344\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0032091701049823318\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018476479644770734\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014910484672547318\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001391591137694195\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0007704146301257425\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00011455312500474976\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004946525695803576\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.000777148803707678\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010749506094364916\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001565685282892082\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0004331150665297173\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0030454823303269225\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013813114224246237\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004049012713623234\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0323277328491211\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005137422482296825\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.024346058303827887\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008801399536128157\n",
      "Current state shape: (13,)\n",
      "Step reward: -8.762893676757814e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.001682887097168714\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.001682887097168714\n",
      "Current state shape: (13,)\n",
      "Total test reward: -0.24403100076607676\n",
      "[I 2025-07-03 14:38:23.466311] Trial 1 finished with value: -0.24403100076607676 and parameters: {'learning_rate': 0.0011161586948051385, 'n_steps': 50, 'gamma': 0.915928229632848, 'ent_coef': 0.006361647962285382}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:38:29,509] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 0.0019362382932219633, 'n_steps': 50, 'gamma': 0.9507537046076528, 'ent_coef': 6.098700867335434e-08}. Best is trial 0 with value: 13.362418366639673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: 0.0\n",
      "[I 2025-07-03 14:38:29.491936] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 0.0019362382932219633, 'n_steps': 50, 'gamma': 0.9507537046076528, 'ent_coef': 6.098700867335434e-08}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1556589.80\n",
      "total_reward: 556589.80\n",
      "total_cost: 2533.79\n",
      "total_trades: 740\n",
      "Sharpe: 0.648\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:38:38,966] Trial 3 finished with value: 24.24192699010313 and parameters: {'learning_rate': 0.0008755584345336789, 'n_steps': 5, 'gamma': 0.986453708167265, 'ent_coef': 0.0002156340756444563}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.01150043190002907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011311620617681184\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08232328254699242\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005980773699947167\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011769409790041391\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08808060928344494\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0028213314773514867\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05718793594359886\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.061460303955082785\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.047393970947270284\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0030437565612839537\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.19186982847595355\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.26988092315674295\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13149995025635\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06187115224609152\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2011448532592738\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20509358288574733\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3372636444091797\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15475664656829322\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1473570338439895\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7381375774032554\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.539455044250493\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.43604895019531253\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.46078753025818153\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.45941883773803716\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17505280293578981\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0638843190002488\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5036449696899392\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11171651332855691\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3601803870239295\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28932175590667175\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21414076102294494\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7773005214386038\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08479602859497537\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1016706268310547\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.572974458496098\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.26808025085448756\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1201106430053711\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4985548092346173\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14675244583130118\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.297006347238156\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7163659878540086\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5722496354187024\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.336909968414309\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6014314281402622\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5730611018371535\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5567667675781297\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6202109646606492\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11974465164184804\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8937509599304176\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2628571070800768\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7623267152404762\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5890749920898467\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.44826257124633995\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3487556922912598\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4318572354125907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6679162542724516\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22089676895141602\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1154559126281645\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5782894644897664\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9489358757019043\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4783386682373006\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2105659638977144\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7436103073120117\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3643811387634371\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0971520243835635\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5138611833511153\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.30084423095703827\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.3814119902954087\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1558440663497895\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007722686541755684\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5631982437637402\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5373953691100934\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4667452807617141\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7638755568298512\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1464514886718942\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7618931887817336\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006599421386723407\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.3134459818618605\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6424055568618933\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.046415009307861334\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5341501777648926\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5445593359680148\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8258609843017534\n",
      "Current state shape: (13,)\n",
      "Step reward: 3.9294502730804264\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03711840655212291\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9053699342346052\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9356203834106448\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09949572647095192\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5123816436767579\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2747586693405174\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.000868857870483771\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.34098944335936104\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3053949937683065\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06020808517457918\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5412066084991443\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5022901844040026\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16031867401122582\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6677464208862279\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4238682933166624\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1084142196655273\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03193962844847702\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7404729882812362\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5322740009460598\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8519257528366289\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22814459213255905\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8658841522216797\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7297127973785391\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24733188127442265\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8095505785888528\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3069641326904297\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.40928551025390625\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2951387797546574\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6958604318359402\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.057117141744983384\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6713517486572266\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9437657653808595\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20461107177739032\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8941656828338048\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7508795867004432\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7571294180297293\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2170425226440886\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.7997048461914065\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9651589965820313\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7223300170898438\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.30683140869140624\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7223103149414063\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3231371826171876\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3377884081237251\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0797090715530095\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.48410225847624244\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09431089477995411\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.0728400151062294\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16308305636295117\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8649568479919109\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2600404165832093\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7550755324493396\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5165661630401621\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5559110198974144\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5623220825195778\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8179176574707264\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6677921478271718\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3962056396484375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5367763122558827\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.9252259510238423\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8980897872803267\n",
      "Current state shape: (13,)\n",
      "Step reward: -5.86648869538263\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.000881499658199\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6067818550720113\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0167652565063443\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14166611671752763\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.038191942059318536\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0504448287963868\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2879229990707246\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5573494407592807\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.6461600930770859\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3121976366119227\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8634831510314951\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8738707667541458\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.4869526349411113\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.0324846313476566\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4268821836730932\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0080143142700195\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.4815522555999694\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.256240587776201\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1406923568725353\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0105807653015713\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.152747504820209\n",
      "Current state shape: (13,)\n",
      "Step reward: -4.34291642193608\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.421670011901809\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3965038009643555\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7547067581176758\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.957073699951172\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3366905899047852\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9616312371826266\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.46162257462465206\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8914913572937018\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.692008747329726\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.2485696060730147\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.971400111175538\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5417423704528949\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8210502954910277\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.6362723983612146\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9788697647094727\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16635655975341798\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.33267373352050783\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6209649522705236\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8639438375473023\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7919117019653321\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7978843407867244\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.65033212890625\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9595006896972657\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.38337894422912505\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9017504409027286\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.574314503637678\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1825670674438356\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08390519547425211\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0042756164550781\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8379448364257813\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24309201660156252\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.6503419738769531\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07441895975037478\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2800224263305543\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.4856230518081692\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.6938852208557074\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8489821135742125\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3238992019043072\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.30704494628906254\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.0435949065704366\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.2741598726806695\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5856145068176324\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6491922408859245\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6490893778106663\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6837513691467699\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3069399261475541\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.7085157775879374\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0199843464111444\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6898215693847742\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3649580383300781\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0804862237228547\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013457442855881527\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1266423903870164\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5185690338134766\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.42894273376467174\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8578854675293202\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11525068359375\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.39052583923339845\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6594145797729493\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.37132723236088644\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8258845092772972\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1587948471069336\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.5544676361083987\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7042375701904298\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2484211471557618\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.913441340032965\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5955453104980524\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9633074245666386\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.0768134678649486\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.095952880859375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3458306910705287\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0755746429443127\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6722366119384766\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3350867933502655\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09585764339291492\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6797763120346004\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.352884291381808\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06358097801206168\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27309129730525894\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27309129730525894\n",
      "Current state shape: (13,)\n",
      "Total test reward: 24.24192699010313\n",
      "[I 2025-07-03 14:38:38.948294] Trial 3 finished with value: 24.24192699010313 and parameters: {'learning_rate': 0.0008755584345336789, 'n_steps': 5, 'gamma': 0.986453708167265, 'ent_coef': 0.0002156340756444563}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000109.35\n",
      "total_reward: 109.35\n",
      "total_cost: 320.53\n",
      "total_trades: 68\n",
      "Sharpe: 0.091\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0050666169242816975\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00043197439956711606\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:38:45,068] Trial 4 finished with value: -0.01326896770321763 and parameters: {'learning_rate': 0.003982275801742689, 'n_steps': 50, 'gamma': 0.9232818091538012, 'ent_coef': 0.000915790429069162}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022263337986753323\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0006402327056857758\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.010393551452632528\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02130905657958938\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02048251953125\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011398273254395463\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0021025290527381005\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00029250274657970294\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008196657209773549\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013149969030765351\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018177753729245162\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005926286163332407\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02337150131225353\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0013560088867205196\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00011479775696061552\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.004196578683471308\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00031298904418945316\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0026382975341752175\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0004907114196801559\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0003404016357380897\n",
      "Current state shape: (13,)\n",
      "Step reward: -4.943102416582406e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006659002227778547\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0009370035858126358\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0026837509246775883\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0007523036560043693\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0018539140090928414\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0007467186935478822\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013933534332271666\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013546701747132467\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0012587959289550783\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006857712469482795\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0014918152343714611\n",
      "Current state shape: (13,)\n",
      "Step reward: -7.702875976683572e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.021707340850832407\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006634733337396756\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0012253901824937203\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008466147300717422\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0004130034362780862\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 6.731163940858097e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0003911434890702367\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01685141475677956\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013930332693480887\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0016377886383095756\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0009950756973237732\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00015711293793283404\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.004724740405275952\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00047311143188271673\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0028397197082522326\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018230119738774374\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007788020057673566\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0037292621917673387\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005681632598862052\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005511729034478777\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0003189371154760011\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00014743673248449342\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.7433201603125782e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03257652797698975\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001240940551762469\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.016643557006830817\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.015351128540036734\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011328925167850685\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013334763667301741\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009742811328126119\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0018132151794387028\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.017733780212397687\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006858594328304753\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005768397750798613\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014559939332585783\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0013719566345214845\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005084396301303059\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0009941658477764577\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00018925407410133631\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007305886477662717\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005177941314643249\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00220459989013616\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005083215026883409\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012400851303106175\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0018834871459985152\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: -0.01326896770321763\n",
      "[I 2025-07-03 14:38:45.043707] Trial 4 finished with value: -0.01326896770321763 and parameters: {'learning_rate': 0.003982275801742689, 'n_steps': 50, 'gamma': 0.9232818091538012, 'ent_coef': 0.000915790429069162}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1063187.83\n",
      "total_reward: 63187.83\n",
      "total_cost: 6028.36\n",
      "total_trades: 733\n",
      "Sharpe: 0.571\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:38:54,988] Trial 5 finished with value: 4.038236548435932 and parameters: {'learning_rate': 3.038155668710712e-05, 'n_steps': 5, 'gamma': 0.9785648961383239, 'ent_coef': 0.000968578054432026}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010123125608824194\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00031318439788883553\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009387752215575893\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0009844714477541857\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0066681380676222035\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2929760746192188e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06077901458740235\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08322507608337328\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04921282562256092\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03189936462402111\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07344082977294457\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07687755606841529\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1046786072692834\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.055582600051874764\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05471577438659733\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2747414635086083\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16929177038879134\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15684900970458984\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13674628156585386\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13108719290924492\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.053582035212707706\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.019634606811520645\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18027205736084143\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.038540178604121324\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1427443838501\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12726921432495583\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09860651956787334\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.38419814437866445\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03471269424438942\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04034372814941453\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20527938761902043\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10238998901366722\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04539443397521973\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1661087911987328\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0418849200897268\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35558698611450384\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1829477540283231\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14688858800353483\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0898215452026343\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17647054293517722\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1789182688858011\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14656336791992655\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1494250574829057\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02705957853241125\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2106832630996709\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.056001356201176536\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13027462848358556\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11065616885985947\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07962268101348309\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0584500236282358\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08090707845458528\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1191466478790273\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.035852833786013075\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1962440867980942\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09074546970215161\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13305163459777833\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0778548754882766\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03287309230804676\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1100552763671847\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05824463185729692\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17950543513031444\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09755311904906994\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05204608608398121\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.41049869976806225\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02888097251892323\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0007419462554971688\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09419873076629592\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09438484700469998\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08299804582518991\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12300139038085472\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.023033879464725033\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12605465954284883\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0022169120697071777\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2825103715515114\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08849026260375976\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006986171844485216\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06255873432159424\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.055013181762699974\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0853991528427112\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4511574932556134\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006476984558103141\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13650243392944103\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12006327331543434\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01308903854370583\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07708592623901786\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03852034496917622\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001294768591306638\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04495959692993202\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1756958904708852\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007623878381343093\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08725717530212132\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2299812677429174\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0254151797485305\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11018122466583737\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23655869815215702\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1761801875915495\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006771729673771188\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31466657224120576\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09302624216919067\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14985568710021907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04588632949829335\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1635355362548842\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.34838087005615237\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05173105377197499\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.37195495336913736\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.061056191368098374\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08076422700500116\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24414316443786957\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1404207323669456\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008744834594731219\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1192858166625956\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31122199598998995\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03515939456786728\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14442546077575535\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2542364025878953\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09557453216551803\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.024430503692640923\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.371937265167234\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13106039890442045\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10366080961304251\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04590639075317886\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10838807352599689\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1938285735992482\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.052309688214107884\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1589019154510461\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07592735532074003\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011629632110591048\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31918049535064497\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.027096925936895423\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12639318077239442\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2049353618652327\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11998496471099789\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0713998161315918\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06820495864866534\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06029216125489911\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09734688175049377\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22057983276366722\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04695927056426881\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07097646014251514\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24780609691161665\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1308805013854988\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.822915912045294\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2925327965942328\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07714280197143089\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1337386688232422\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.018908429821778556\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004935013316350523\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15451613378906623\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18752371368408205\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09016713158569765\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28661230361938944\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05575289364623605\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16441871228332167\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18264000503539574\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.494244213729864\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6068105966003379\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2646681802429143\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17116383666992188\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.42159262112731816\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.37165734390259025\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.019142032775876578\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15959063294677764\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02232915265655611\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.612486997924815\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5364659280395369\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05404887435913552\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11367693122864003\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.33033360733032463\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2240254284942639\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1531593776001013\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08258404434204568\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3554076870727586\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12739984370422316\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.38332193542480236\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1686716795867891\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08639353939361172\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11669606948852307\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.37994139474487165\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1315140451110783\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018773334703058937\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.043674681701662485\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22864731481933268\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12768831600189443\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12243152716064361\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13178067108459074\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2724946076049819\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1675758533752407\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06751531982421875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1534653209457407\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08861697418212425\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20500480102539295\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014387511532590725\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1735041791931144\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15824343353881268\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04428456773528597\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2931848434341373\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010732174987788312\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03954964050293202\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1994879741195706\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.39078234344482193\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13455715576171642\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18980536346435548\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04443134702300886\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3260494938705466\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3690299995117239\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08857228275756351\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2597841041015578\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2693243854171713\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11695012192993891\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05539661288300995\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4391127166748047\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15695196096801664\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25178963903503027\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.051575266921997535\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14994271376953694\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0018345906829927117\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17196405059815154\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07534193668822992\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06086918813324301\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1332532819747925\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01906926346587716\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05431189376830589\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09791742931365735\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05288698802491417\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11460151098021307\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1562345576522872\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.36000350885009397\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09048219024657737\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1480639774292009\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11326661938324105\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2207584015838569\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11549129089355702\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27972864425658484\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012525270080566408\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.049682149276719434\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14465822947082344\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07833172835693696\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17390475231934108\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01570835937500233\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09929840666961391\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.048966584686283024\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007819288635253907\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04204151034849929\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04204151034849929\n",
      "Current state shape: (13,)\n",
      "Total test reward: 4.038236548435932\n",
      "[I 2025-07-03 14:38:54.970019] Trial 5 finished with value: 4.038236548435932 and parameters: {'learning_rate': 3.038155668710712e-05, 'n_steps': 5, 'gamma': 0.9785648961383239, 'ent_coef': 0.000968578054432026}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1053710.80\n",
      "total_reward: 53710.80\n",
      "total_cost: 6074.02\n",
      "total_trades: 735\n",
      "Sharpe: 0.481\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:02,682] Trial 6 finished with value: 1.0075651276146638 and parameters: {'learning_rate': 4.260252013784138e-05, 'n_steps': 10, 'gamma': 0.9464209396656843, 'ent_coef': 0.001352047130861722}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.007245272097014822\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.015572046699526255\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06103424410858425\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005370521113590803\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0024552329345722684\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.026926119821169416\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0013257243347121403\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.317039947025478e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005262745220947545\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003760997067263816\n",
      "Current state shape: (13,)\n",
      "Step reward: 4.829064178047702e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03376629420471145\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03285720663452521\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008722683734132443\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008697075476078318\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010713435253908393\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013594965019228402\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013390961639408488\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.017053572845458984\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0036399745178176094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009190323619078846\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00026800438843201845\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02887097625732422\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05342243113708683\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07968370590209961\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.021194993743894157\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006538943762204145\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02153227355957497\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011946331634523813\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012384699096682016\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02250710657348391\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.028357849731447643\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05543094161987538\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007422859109495767\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01286790771484375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10679878997802734\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04254530668945518\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.017758920333860444\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09468375457763906\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03113168472290272\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2907037479949999\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17070705427245703\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16004960754394998\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0916111829040572\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1437570104980492\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12329633524932433\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09642798964843387\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09287673200988211\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01221437515259022\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07726964656066848\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.019642517248529476\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03723934203033569\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03435456069336506\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.039697562409972305\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01671119613647461\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.024221882873540747\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.018724791564943735\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005871447944641114\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05797837966919178\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013030661315913314\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025236083740228787\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0015048291015671567\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.642955170245841e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005532415338139981\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00416234638672322\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00019224263306241485\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0050971592712448915\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0009941642425488682\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.029024453152460047\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.015902118016057648\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.026074504394526594\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05837611877440941\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00726687538146507\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.028935473937983625\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0016954785156296566\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.037175508978276046\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010606384796136991\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0012920378723181784\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013823267364501953\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007598333877557889\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.028244364776613656\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10968788105163257\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0010714708373998293\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01647418813018594\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0015624574951129035\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7907276912592354e-05\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00018896900940453635\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011584771606489084\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008608454284665642\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.033989096617128234\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0011374215454095975\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01591990041045938\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.042726915599056524\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00027154798889532687\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.017427809600834735\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.054276737931824755\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04407682937622304\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0019017607009853238\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02847196059570415\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0012721743774367497\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00010749374084407464\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005006162396236323\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.024623851867672058\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06816986415099818\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008077415722655133\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06246570612792857\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0082811514572124\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006679325180058368\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.027337419821170626\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.017961760266113562\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0004090611022897065\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02511803909301525\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09569800842285622\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.015285202941892204\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.056526894537347834\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13683611877441873\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06122843773498899\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01857377456665272\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2097486634826637\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06982797858886189\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05937826925506816\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.026790741207881365\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05694503921509022\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08222708221435314\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.027684340209956283\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08931286974945106\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03158869918823475\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0031486231994582344\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1116846168045071\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008150500793452375\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022297046954347755\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05537411865234608\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.045976540985109754\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022156862617493608\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.015413894523622003\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.019939969171141277\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01928777648925316\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03875241129760398\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006846422225947026\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0183757213790901\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04095509214783088\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.034294526977534406\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17793620287170633\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06752935477294959\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025889724153140562\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05935762985229958\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007515469055180438\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.001499932154850103\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.036619053771975454\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.026870862840267365\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01717776954956353\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07436737106323708\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.016977993774414064\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06318440139770974\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07887270767211449\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22359747821807396\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24725103256836303\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13621001770019067\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08676150970458985\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25575805847167504\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.19451003799438477\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01235045760498615\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1000877590164193\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010969884185795673\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4050352990722633\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3363474757965072\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04083651552123484\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08079188548583771\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20709752047576477\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16378354019165273\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11625311951293843\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0644731304580695\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27348285316772525\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10335626554870979\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3034633462524391\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13542103952483742\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07470672960815719\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1163636499603279\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.37842973749542147\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13481194276122843\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022618569879152346\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04550546627197182\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24585898436278805\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12561970592498548\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11031949931335404\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09605814239501488\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17450254577636953\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09381558402099181\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04221675809326116\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09388265778351343\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05659393249206478\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12296381511840737\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.009042613677983173\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0774434081268264\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05227716018676292\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012631973724369892\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07747401474457001\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0028674752044724303\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009104998315428384\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.037213948149106\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03786689760589507\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.023135158691403923\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.027486898803710937\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008071898902894463\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06593406636657892\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07934995837402531\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014010112969973126\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03933208056335571\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014542332403559705\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.002711665173340589\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00804718887328636\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09238131912231912\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03965743155822857\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08910679794311291\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018431130615237636\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07087205245972146\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011269223785377108\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07409208577880637\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04101531433715718\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.029269036697386765\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05100507141113049\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.010321045684814454\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02167490263214568\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03428221386566293\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011017772216792218\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.015169607855228242\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007648448333737907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0006017691406304948\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01570423425292829\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025231716461176987\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07477917572021252\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.028822587075806223\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03065333297729958\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0010281997680664063\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.010198059310915416\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.027891620700072964\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004830869140627328\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.025753247055050454\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005180385437014047\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.036026326751708984\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02252975958251627\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0009417373657226563\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014645481262204704\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014645481262204704\n",
      "Current state shape: (13,)\n",
      "Total test reward: 1.0075651276146638\n",
      "[I 2025-07-03 14:39:02.672334] Trial 6 finished with value: 1.0075651276146638 and parameters: {'learning_rate': 4.260252013784138e-05, 'n_steps': 10, 'gamma': 0.9464209396656843, 'ent_coef': 0.001352047130861722}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:09,224] Trial 7 finished with value: 0.0 and parameters: {'learning_rate': 0.0037059097552619054, 'n_steps': 20, 'gamma': 0.991137044469336, 'ent_coef': 7.354904835529772e-05}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: 0.0\n",
      "[I 2025-07-03 14:39:09.211289] Trial 7 finished with value: 0.0 and parameters: {'learning_rate': 0.0037059097552619054, 'n_steps': 20, 'gamma': 0.991137044469336, 'ent_coef': 7.354904835529772e-05}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 995570.26\n",
      "total_reward: -4429.74\n",
      "total_cost: 1814.11\n",
      "total_trades: 274\n",
      "Sharpe: -1.061\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:15,238] Trial 8 finished with value: 0.02659985732272034 and parameters: {'learning_rate': 0.0029835005695534765, 'n_steps': 50, 'gamma': 0.900691369889667, 'ent_coef': 0.006618307783923436}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.024331712341308594\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0013610690307570622\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00234349686432397\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00018728303527459504\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.019473119812016375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0015086869811988437\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012227420196530876\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001821364135737531\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00047595062255859376\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0019666976928710937\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: 0.02659985732272034\n",
      "[I 2025-07-03 14:39:15.222639] Trial 8 finished with value: 0.02659985732272034 and parameters: {'learning_rate': 0.0029835005695534765, 'n_steps': 50, 'gamma': 0.900691369889667, 'ent_coef': 0.006618307783923436}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:21,767] Trial 9 finished with value: 0.0 and parameters: {'learning_rate': 0.0029909548557308947, 'n_steps': 20, 'gamma': 0.9803321300944643, 'ent_coef': 3.8865974280876416e-07}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: 0.0\n",
      "[I 2025-07-03 14:39:21.757215] Trial 9 finished with value: 0.0 and parameters: {'learning_rate': 0.0029909548557308947, 'n_steps': 20, 'gamma': 0.9803321300944643, 'ent_coef': 3.8865974280876416e-07}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1318187.45\n",
      "total_reward: 318187.45\n",
      "total_cost: 5270.32\n",
      "total_trades: 735\n",
      "Sharpe: 0.480\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:31,268] Trial 10 finished with value: 17.495982108274898 and parameters: {'learning_rate': 0.0002643125629452641, 'n_steps': 5, 'gamma': 0.9655903572111191, 'ent_coef': 6.581011390493182e-06}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.01150043190002907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.027415134565730116\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09079868000641\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014417320938105696\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010166254272463267\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06124337931213668\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0032382970626815225\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.051324111480708236\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.056334534912114036\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03461837415160844\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.002083908538823016\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16440149653624977\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23661539581299296\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09042560220337473\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.051279497680661736\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17564790832519067\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15878243709563977\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.23720205897522392\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11574734420776368\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10894571004486643\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5705815476989723\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4253808987426805\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3397897951049847\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.373832071476744\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.34934192831420807\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14620781723022228\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05323868148804177\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.43496053876953666\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09886167533874977\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.342601154174807\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.26329750191803325\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20142911590576407\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6982982603637735\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07654800918579567\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0844777349853539\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4649045491638128\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21425335327148207\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09418999046325917\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.38414635218505283\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11424337600708241\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9699554517562851\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5015253985595657\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3928206402038574\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20933170913696522\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4025492407226586\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.34939984896087556\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3449359171630815\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3765784649047884\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07267231264648727\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5310758602401707\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15421218516845256\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4474953051986639\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3656159083007835\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2989148347473121\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21313188400268557\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2691094265747117\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4250294393920922\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13908712337494364\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6767135158905061\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3519930068481481\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5720069973449688\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.29449255622864\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13272038589477306\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4597473146362347\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22468148277283181\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6865580546569778\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3340865586853004\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.19772466308593284\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5498078211547808\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09835691163330339\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0043376397369429475\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3231372312927386\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.30862613717499193\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.27083593044434673\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.46595046264647977\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08974159637450939\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.47685407745360864\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003279129592899699\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.453969856414781\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.40842880020141603\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02974708104704041\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3457255081176758\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3707830944824265\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5588922021453852\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.6929597402954126\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.026648378906259314\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6351117250060896\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6545776282836916\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06961293898466975\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.35571696917722\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18666899847718887\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0009540400146506727\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2304370425933972\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8979245444274974\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04144570293882862\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.38410830551148395\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0780327729721089\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11255662486574147\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4634846242218046\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9831909494354157\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7664739093475277\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.021579804942314516\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1691032128906345\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.36127765777588355\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5937309788513231\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16531586441041438\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6256727515258826\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2607634323120118\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18112620452882258\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3535145413208054\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22987854309082031\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31102646560668945\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.02550814926147\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5562231640625047\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04482874267578591\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5518794614883373\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6228995404052549\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1734864220489748\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.775433827651944\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5566889630127\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6605064021209488\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1856664823303465\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.4482982942199802\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8615338900757022\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6462198434356601\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27669565541686025\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6681565092468169\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2133882049377542\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.31760014984128065\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9995415876815794\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4462360960388091\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0869041560363723\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9836619269974065\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15805902995611543\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.813684945526137\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1760238492736594\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7218541861190927\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.48925312980653257\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5254674305938417\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5265700153747807\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7758387834595051\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.555804931536899\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.36813457352751866\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5033521850540303\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.834908350788872\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8443318330200389\n",
      "Current state shape: (13,)\n",
      "Step reward: -5.5566095212219055\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.8764014782470653\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5729821422958514\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9591513861084124\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.134783282165532\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.033970049896254205\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9766527773437557\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1992606077575825\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.534721432189946\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5328187443542296\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2947332316589309\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8180626898117132\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8273274837432663\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.3112856576995924\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.789666243041982\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2909395484863315\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9200459457397462\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.321819003924541\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.1170818367691013\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13219750127561858\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9623833465576638\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14525644683835562\n",
      "Current state shape: (13,)\n",
      "Step reward: -4.057402640991239\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.1839333478973018\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.37031002370605715\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.713569713644404\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.8539261169433594\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2643430238189641\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9267810178527842\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.44227728424072266\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7933438919067384\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6537717277526855\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.170361944143684\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.936755579925538\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5159095414413373\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7805147828063927\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.489085684310901\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9107962057495141\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15538617538452382\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31144396692810117\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5381416211914039\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8134971233749413\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7509744422302232\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7557451282104478\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5357963446045062\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9033583718627924\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.35838205594941974\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8397189000854501\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5421088435089216\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1281132674499414\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07872661743164062\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9454893364685122\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7939356951995986\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2301311279296875\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.546378746302787\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07152428975830553\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2664764144897461\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3957569126892138\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.4784675542144803\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7941226342773531\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2456860321655172\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.28475351655578707\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9102626647262602\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.1690259946289006\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5472110025024275\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5113080436965918\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5422380839538528\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6254521429443499\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28795736648563763\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.5611742172241443\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9698917225738755\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5722110520935386\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3424176391296322\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0295925240936223\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013289183120732196\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.065196198712173\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.49082731933593754\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4059957275390858\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8119914550781483\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10918393630981446\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3677499064636184\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6241380981445313\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35146246337892956\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7733279516738607\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0865610855102539\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.4167402325073257\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6645832154602046\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1561083502197407\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.863034842114267\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5336643022705336\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9097110922241352\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9492026468291879\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08974420983886812\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3236097640991211\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0193291958617745\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6358572387695313\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2737577414398549\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09096773742672522\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.643429754798906\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.33486662170407366\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05868587608335074\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25360094221495094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25360094221495094\n",
      "Current state shape: (13,)\n",
      "Total test reward: 17.495982108274898\n",
      "[I 2025-07-03 14:39:31.255526] Trial 10 finished with value: 17.495982108274898 and parameters: {'learning_rate': 0.0002643125629452641, 'n_steps': 5, 'gamma': 0.9655903572111191, 'ent_coef': 6.581011390493182e-06}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1059823.75\n",
      "total_reward: 59823.75\n",
      "total_cost: 5812.84\n",
      "total_trades: 740\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:40,754] Trial 11 finished with value: 9.248086748592305 and parameters: {'learning_rate': 0.00018099763216142522, 'n_steps': 5, 'gamma': 0.9656522514092235, 'ent_coef': 6.32055804905393e-06}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.01081040598602267\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.026910939102177508\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07643718965530862\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012795303268427961\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014840911120607052\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06797632209929871\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0022748779891990124\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013566418000787964\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02313353088379372\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.023683340148930438\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0003719919860828668\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08439275970458984\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13745853546143044\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07144436617431929\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.042283941040036736\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11550634500732414\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12713068161010743\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1895473071594257\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08409153315734584\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06171202041625511\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.33527358345184477\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1917832058715867\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17435027923583984\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20814637357330648\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2161504287490854\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08995799189910758\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.031012935156247114\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22653753511962715\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.058033686981198845\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.19966915098876925\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16492893693542574\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11683314440917457\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4046159539901768\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.045511647491459736\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05690591735839844\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3024004689941416\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1329943966186489\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05851432843017392\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.23549360294799554\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06851682019195286\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6000355015014648\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35452324707030786\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.30711305206299294\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18332757994994756\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.32465023981933483\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2998097882751492\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27467868721924027\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.285850410076906\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05579846725311363\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.42590017100829863\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13685157287598124\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.38915136467284756\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.291715151568607\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21303891311645276\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16517201520538657\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2106402859497117\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3371375173614477\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10266564102172852\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5299563917541528\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.253556952209468\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.41487754784392894\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2015908339630114\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09299671646117931\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3124748084106483\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1396909684753395\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3885588847351028\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17166521143799182\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09459857546386775\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7425137433410622\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04631829033355462\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0012146281890920364\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15774805282593007\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1464735501403804\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11663405185546727\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18161994826659794\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0349035184326116\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.187279488003545\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0016989319061278367\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.493078834686277\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1315520929336548\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011916809844970703\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11783855075836182\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11288637054443826\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18654521309662378\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.826065646984859\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008329849765019026\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2090274217224098\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21217107912597713\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022708569793705828\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1203053113861126\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0705687815856887\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0016354971679742448\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09566450133362087\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.36782782374420203\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01651048995971214\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15143325668334728\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3872714921569801\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.040913923956302466\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15508954971313943\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35509895034789807\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2613134497070336\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00888421778412303\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.44814253173827895\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13540910178222695\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20416864974976054\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05439519355163211\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21893714599609376\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.455111387634289\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06259092633971014\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4650107554565417\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0782645166061353\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10809030773162377\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3720311900329544\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20451190173949582\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.015863610534649342\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21868523574827706\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6340771929565585\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06651195780336858\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.30478803019714545\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.600758187139919\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24261291107176805\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0677997041931143\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8575943592163036\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.30747779561767824\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24223465377807152\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10002646368104033\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24536097135161983\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4302619535308797\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10924879145508166\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.35169736168822274\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16622140792848078\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03234943496701308\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.772196560708643\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.060881633630394935\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31176914239043835\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4409884127807338\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.26730649488680064\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1765492780990666\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18659791278534105\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18918382282103413\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28985706665038596\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.591898085388192\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1439379772842396\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20451992397918367\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7272568831222598\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3541242236328079\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.3646025585845813\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8411889135742211\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.26128259794921616\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.44710692827148596\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06396326012267964\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01699971739196917\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4905805233764695\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6081104152175948\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.26596677991332257\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8038478535461473\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14634495391845703\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4196109577941941\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.43681999271392125\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2605223747253418\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.557121989862062\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7393683169860858\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.521496762084961\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3294528214569088\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2101070675353987\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0757810113525251\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5750945042419713\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0872728504241677\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.5586111572265624\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.0693486337280134\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2407267575042788\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.46513021005553895\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1832469720611583\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8158329337325996\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6101745523071149\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.29348311750944706\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.21642404754638\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.45003112531279915\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.4870915580780013\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.655833296948229\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3555536930328235\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5213604713317939\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.6800056856460637\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6170261416625931\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10505478909607045\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2045211172485375\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9841651634033187\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5385130612564041\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5118395950317383\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5050959095489467\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0359598622314399\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5966006710693473\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24545579157257455\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5706031036605826\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.36683419682311363\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7351894369567745\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.051655395274353214\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.593099068603525\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.49237922856598165\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1422087671920657\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9474754641586333\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04361678093872033\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1653533364624018\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8942937169128448\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5905526502838125\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5031785949218786\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.762255932006822\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18019728775024416\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1871548708679271\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3431071787109365\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3394961092407233\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9415636751998915\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9550402221115074\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.40363755096439274\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17893420822148912\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5995280503845426\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6061634358307114\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0244662400817965\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22157762451171875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6692964669311652\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00909869705203455\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7197136462402763\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.332692965573119\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.26672505250549877\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5523612892151112\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07402170758056455\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2438389074859675\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4247989347839263\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24202488281251863\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5311660478957929\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7620156163543695\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.704246324255364\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.48036351308899466\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8565420589233517\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6367069693496916\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1467286386108726\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6960191592895659\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4996288523833967\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06879664816283622\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25595750579831655\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.808850796203618\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4928050079528941\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0030794879150577\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07317070010984317\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5152381945571862\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.26136454169310164\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.046902976608253086\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20719769844051916\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20719769844051916\n",
      "Current state shape: (13,)\n",
      "Total test reward: 9.248086748592305\n",
      "[I 2025-07-03 14:39:40.741645] Trial 11 finished with value: 9.248086748592305 and parameters: {'learning_rate': 0.00018099763216142522, 'n_steps': 5, 'gamma': 0.9656522514092235, 'ent_coef': 6.32055804905393e-06}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1043798.48\n",
      "total_reward: 43798.48\n",
      "total_cost: 6023.05\n",
      "total_trades: 734\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:50,161] Trial 12 finished with value: 8.088743164145601 and parameters: {'learning_rate': 0.0003959282619821803, 'n_steps': 5, 'gamma': 0.9942996347381023, 'ent_coef': 1.6885651688796218e-05}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0060952289070119155\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014828227915952449\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.056542444398498634\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010493084640498274\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.017101163604739122\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06493184692077339\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0022064354125992396\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.033675262265012135\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018866374365228696\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.020944726257328877\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00039739251555874944\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03987298554992304\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01719085968018044\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.019367007730097977\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00451583190917736\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011676999694819097\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0056593982086167675\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01291442536925897\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0006211539001436904\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005799596379091963\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08316963973998791\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03809816500244197\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03676638882446569\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01893169938965002\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0010534392013563775\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005220898565673269\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0006553390319808387\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005563595962477848\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.021019185485842175\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03469096420288552\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03673041595459217\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16528828109741445\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011584227447514422\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011019772827147972\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05864488984680502\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022041137438965963\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012862313781736886\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.056497589904780036\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.020512846221926156\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20205683186340612\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12199810994872824\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1028600981384283\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06944767288208241\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1446863756225561\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15378417770385278\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1288894472656306\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1592819622802781\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02486964859009022\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20359877785644495\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.059391034484864214\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18302378128509736\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16127287536620863\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13227093884582863\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0897681776962243\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12071787994385232\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18924584742431763\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06433645214081044\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.29553190634307686\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16520677215575708\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2899609733581543\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1567123034667922\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06844449361572043\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.236509969421383\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11432292211456224\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.35789068190765105\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15701435853881995\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08377221491698875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6722733665588428\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04534091636504745\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.002204450097656809\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1717246031188988\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15626944747162053\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14399366333007346\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22820813590697944\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03852234588622814\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21229225238036598\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.002267380026250612\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.65137776999817\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1674010487213149\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01239635953521356\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12750131435394288\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14136135820923373\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20390538202972386\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9831352939178469\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011258608398435172\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22741302292633336\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2373602027770947\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02534480884857476\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1403419217376737\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07365026015625335\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011584771606489084\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08915053908386035\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3620375398406992\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01637438443450956\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15308871554870856\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.43795155436401256\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04203416868896457\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1785507470672601\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4014820558166481\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3132075359344483\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.009572462167358027\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.44481896245117536\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1363336825775099\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22536451410980662\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06607211898803944\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24882340875244702\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.49216165078735213\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07062261579284677\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5413886952026398\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09867568069457776\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1336630744934082\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.41384229385375515\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2160909406188992\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.015052836303715594\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20922518478393323\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.597593712725828\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.062317371087661014\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.26283526124877393\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5434554547119187\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21893124908446335\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05804755700684618\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7651647516067606\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2669005936218426\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1997529618133558\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08370490427550395\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20749200260313228\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3589053964233492\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09738513764645905\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.29902701445769053\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13987053848572542\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.027061800689669326\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6022335926819128\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04721988604126964\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24200223146665376\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.34587169069210066\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22000478960876355\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15480484542846681\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1577846705627162\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15090495422366076\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.21949072600100192\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4376548663086025\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10819004359894899\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1503544511047425\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.573427988739009\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28181004516603425\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.915131412048312\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.676118595617672\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2086253409820609\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3627506739624078\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0513267587371869\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011575135537714233\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3612696970214835\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4307287371566752\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.19841990552978825\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5846397655654931\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11447686309814453\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.325632431901549\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3429680262588547\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9994275978088379\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2687379522705102\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6013459185668966\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4143538345336914\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0708610919189407\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9966505836486701\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05830207625122275\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.44070741338350344\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06714522750852629\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.920171130371117\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5670510827636464\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.177031331275939\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3350345922485343\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8806783951675403\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6188568692184403\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4526966391448863\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2213343152725138\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8622158856201219\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31295230322264833\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0385878829711932\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4694410218811012\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2593999402114889\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.40074656997680436\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.254546808753966\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4585248414978036\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07385118406371913\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14545240834350698\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7314930680786144\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.39463513622283936\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3588195997161791\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.342924377746589\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6897641920715338\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.41493606445312037\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1666765869140625\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3973093438262935\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2541348750793492\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5211973446289078\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.037343215621949644\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.46066966335754844\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3751356744232122\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11398310897827614\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7824801739883377\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.033435092468257065\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1315012335205218\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7018435906570522\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3052066764831542\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.42333132568359144\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6527798662109301\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.153673161239631\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0123003567810054\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.109670704467781\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.29482611633301714\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8447251155029284\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8735843180847238\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3701701509063947\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1651631148666842\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4119662846374792\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5489972934906139\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8946926616226324\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1970837944030762\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5755780602035578\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0069005802155006684\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5891092967956792\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28148881729124114\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23202731738281437\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.45325682754516605\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06162833077241667\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20856164878082928\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.36018174792937935\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1988569420898566\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4360451820907416\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6086079006027197\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3781419934082078\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.38251089653319215\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6883613496826031\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5023701733917464\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9111408700561617\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5337526773620397\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1679466908263973\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05352453765869141\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2034773261260707\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6289039867034881\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.39730502881470603\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8067841846313794\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05773843937681523\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.40652621984863657\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2086310849487083\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03492259674069938\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15282831861265003\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15282831861265003\n",
      "Current state shape: (13,)\n",
      "Total test reward: 8.088743164145601\n",
      "[I 2025-07-03 14:39:50.149754] Trial 12 finished with value: 8.088743164145601 and parameters: {'learning_rate': 0.0003959282619821803, 'n_steps': 5, 'gamma': 0.9942996347381023, 'ent_coef': 1.6885651688796218e-05}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1042008.75\n",
      "total_reward: 42008.75\n",
      "total_cost: 5347.38\n",
      "total_trades: 736\n",
      "Sharpe: 0.175\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:39:59,599] Trial 13 finished with value: 15.840768479109164 and parameters: {'learning_rate': 0.0004897359757336988, 'n_steps': 5, 'gamma': 0.9651941250835612, 'ent_coef': 1.8516711023318273e-06}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.01150043190002907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00903519907760201\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008993399716191926\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0024822279472369703\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006270393243408762\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04963318246459821\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0016502147567691282\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01121022140502464\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02126961486816872\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.014750745150761213\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0004604618835495785\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07021065167236375\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11858674591064919\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06380485868224642\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03630573992920108\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13003825866698754\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10243160781860353\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14539128144836286\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07512371444702148\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07058712480163667\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.38753602767944106\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2338001795532182\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15110640563964844\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1464614336715662\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15994563791656402\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07292086349487072\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025639427886961493\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21689797396240756\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04722327064514393\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15459204997558845\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13527771347046363\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1087574240112328\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.36579355461578816\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.041387637786869894\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04813936206054641\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2932393753051758\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13144651083984646\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.061921122741699225\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2665037186218309\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07869213393555256\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7285324540710426\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3895750790649443\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.29937310835266256\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1810786497497582\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.34557364055785583\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.301751235658268\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2900661841674824\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3322089413452195\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06313121136932169\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.45349443016814767\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14475169799805154\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4107913724044804\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3342189616638236\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25110191107025603\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.19770450817107924\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2503157742309617\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3969815634155297\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12346858154296643\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5961060967529309\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31322302868652624\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5031917267227196\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2625670993041946\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10864058090209729\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.37213426245116865\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18631974044799574\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5748894297958352\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2724188741165213\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15330921237793518\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2448986624145533\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08499399917603005\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0043940028076176535\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2851140255493112\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.27739396377563247\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2375568999511772\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.412445250244136\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0790777560974122\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4115309271484381\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0043554119873093445\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3040180812316948\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.36606222149659884\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.028605469512939456\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.32148674240113473\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3451335247802665\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5411447172546526\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.5608179721405033\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02352475787352305\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.586754699497996\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6217989224243211\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06630296924896538\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.344332483108528\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18898256332396995\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00044294714964926245\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23646295678708704\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.878958108367934\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.040204210525518286\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3666196580505464\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0068107473938028\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10702165137941484\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4509085743713426\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9380264980254928\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7046516391601647\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.021130554046621546\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1266441400146345\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3484206768798875\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5732491154480027\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.154323669874575\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5951875427246094\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1708470413360512\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16804825749206356\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2511485815918073\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2112637305297889\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.28523621902465823\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.932653381925961\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5065802807617001\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03894840209959075\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.48803679672239814\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4359874096679734\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1543632396850968\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6904342899658019\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.388461262207036\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.57934022430419\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16639976385498886\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.1836703025543365\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7529294708343689\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5675123654739233\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24367535217283295\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5911816801452544\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1018379067993258\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2887397525023902\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9296351679992397\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.43015030807494187\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08251923109893687\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8663474003601355\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1516940432739677\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7941609870407033\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1645977133178385\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.702868096917728\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4804565373382531\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5182620553756366\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5206436079468113\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.753303156164568\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5545320011444157\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3668582913436927\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5002963855423266\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.7749096553039272\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8409187030029484\n",
      "Current state shape: (13,)\n",
      "Step reward: -5.475490497601289\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.8434792333984515\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5521625022354303\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9229670263672015\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1298380932617234\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03380941604615655\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9970539252319374\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.188364216659544\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5168457256286638\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5346023152160693\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2883038998413016\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7982237308303942\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8280264722442487\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.3052546980896036\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.7970805089599686\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3189501987793018\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9270213531494141\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.2983978635650595\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.0980189506530764\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12798696770628448\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9465940513580805\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1414971653045388\n",
      "Current state shape: (13,)\n",
      "Step reward: -4.054724850769062\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.194672991006449\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3622904743957566\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6898386042266852\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.7784902178344784\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2297347163711558\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9025728122924804\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.43209935962219026\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.757159855615243\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6563363410568098\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.1225706401916455\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9326628222763074\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5042793110168423\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7649811451049872\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.4611984337234523\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9137938110351563\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15337661286162912\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3085144939453225\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.516337885888666\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7946053810119629\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7508128067016602\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7465472900390625\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5315693416381837\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8952529422729509\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.35662550239409324\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.838075090225204\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.539963590728771\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1113102187866346\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07763104400634765\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9237068505859236\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.766433907203679\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.22458869627227543\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.542581867681886\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07125471424865537\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2625550347290002\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.397749252319336\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.475535549026483\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7825741340087844\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2329107608642547\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.28656938937378584\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9074412203384332\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.108697244262707\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5476094015136828\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5045911576843356\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4882886144699063\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6214675102417124\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2859111003113212\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.5262401501465126\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9558588775634999\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.5771905639648671\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.33916091038512536\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0153025524200407\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011955926513695158\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0321143725586357\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.48372482694550417\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.39323989100649487\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7820218494339148\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10857631912231445\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3558029128784081\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6151896849059966\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3460958996093832\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.75586878921506\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0828703325027367\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.376731455261237\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6463155337524368\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1597864401245024\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8596913774948335\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.487803467712435\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8833417307525641\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8779505867278903\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08416793690491468\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3091598957824754\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9796351712035947\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6195276129150531\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2522748480987969\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08944885009762366\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6404660220184364\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3255030716918642\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05866911201474723\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25672556152341425\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25672556152341425\n",
      "Current state shape: (13,)\n",
      "Total test reward: 15.840768479109164\n",
      "[I 2025-07-03 14:39:59.581428] Trial 13 finished with value: 15.840768479109164 and parameters: {'learning_rate': 0.0004897359757336988, 'n_steps': 5, 'gamma': 0.9651941250835612, 'ent_coef': 1.8516711023318273e-06}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1033294.86\n",
      "total_reward: 33294.86\n",
      "total_cost: 5782.48\n",
      "total_trades: 725\n",
      "Sharpe: 0.335\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:40:09,012] Trial 14 finished with value: 2.5357353283415542 and parameters: {'learning_rate': 1.1024795761328347e-05, 'n_steps': 5, 'gamma': 0.9686669858979843, 'ent_coef': 0.0001018149889190306}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003039970154571347\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00025918463973794136\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0039526908111525705\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009988626318355091\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07936146865844494\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003179817321780138\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03525975197601365\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.024041769201657737\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.015233354302973021\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0010423254455556163\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07156372225951636\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07954327856140445\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04110571708984208\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.020031710180663506\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07923444194336189\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08357069217681419\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13344546049499187\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06514684953307734\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05322564312744653\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2880020183792105\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23210877960205545\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15285283030701102\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13271055768890075\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1537980857849121\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07043304611205822\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022217101963807363\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17654654272460613\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04153760169983143\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13157636329345407\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11465968564758078\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07125291503906483\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28265562324371424\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.030720441265869886\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.030491547729494053\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1896614613037091\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0715249438476516\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.031604399856564123\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12819572617186933\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03431796884002397\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24458225265502698\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1607351000976516\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12304590200805106\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06236686768645887\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09235925048828358\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06659427355804946\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07163536152343732\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.055525774841313255\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009281848240667023\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04485185330505483\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00690431859131204\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008871456565859262\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0006069353576633148\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011479775695805439\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.015362239840696566\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.012590714263916017\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06485270990752616\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04745893432616722\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05163506546020508\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03754717742919456\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01714706405182369\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0698491304321331\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03003653065491235\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08212285977631109\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03375104745788267\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013493596191401594\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08173850231933175\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007859109333797824\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0004029521118151024\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03759830039214576\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.026569828723149842\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.018869974829105195\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.033189759930421135\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0065396986694308\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05160903961181175\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001609547195432242\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16345302646178753\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03970679177856073\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00472966532134451\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05296198348999024\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05647433744507144\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09817519811858656\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4231878878173884\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006220949707028922\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09596370254516369\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0967396155883791\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009737890998844523\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05370152334594168\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.034876333160395734\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0012266228759777733\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03710526131286752\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15699157490539364\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006729722137446516\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07253053794403096\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20171958650359884\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.016904005737300033\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0633150563049363\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11207080398559338\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10398295288085938\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.002827293395996094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18481172551269412\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05699003287353553\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08830773805084173\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02326799655914074\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10127288513183594\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22231905975341798\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03358325536804041\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22516678894043435\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.045067453155515254\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0495120979309082\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1447652777771\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06960982773437864\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005302882681274787\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0736919223312405\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2175129595581093\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.025749831811524928\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12469863616942894\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21775382642822808\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09414365363158286\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025512777740485035\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.34766533665466126\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11105664693908766\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0755327223464963\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03262484836120857\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07129566684265155\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12435157469788101\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03203102698974544\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1091872813003487\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05590797103882069\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011158196907048114\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23647457441405859\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.018296906018070876\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08017557197113057\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0994543951416039\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07000180880584521\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03667445297241211\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.033223591989139094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.027459019433590585\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03141537539062556\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04466764842529083\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0027880781555199067\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.016666037445073018\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.046644738145451996\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02752826058350038\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2672921267700149\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08726376948242542\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.015159435577387923\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04641286682129139\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.010042525939946064\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0018639527679421009\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07416855261230376\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07319665572661907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.028116055126953872\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08519712533568964\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009593923950195314\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02393076975097647\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.020060614311217796\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01752611770629883\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006773539898684249\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00022732758178608493\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006529985046386719\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0008396300140419044\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03736721228027018\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.025056173251348082\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004687072972103488\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011487083898927086\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.051212756935122894\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.015216317596437877\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001122653823858127\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.007991954875178635\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04268472515869653\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008647329864499625\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.027205251339718236\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011205336187744979\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012940862884523813\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.025646218312077692\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1263272346496582\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03280175384521718\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.00607542041168781\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012417644897464197\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03708292053223122\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.030431189918518068\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03156293504333589\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01785904876708519\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.035497920642094685\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010009735382080545\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005619820152281318\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.006282076721196063\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0117502871704055\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04789260009765858\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.004477724171453156\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.052056646261597055\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04713397212676937\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011501663665776141\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09356732192992932\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0013678164672804997\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.008927552270505111\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07595683029175271\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14746426000976937\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05437154270019383\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10525345306396484\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.018669080467219466\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10173245498656762\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1069993865966797\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02598279650878394\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0957043290710426\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0967347867858829\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03837900946349837\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.022448020608525257\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1689624569702195\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.061081424322514795\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11010718480071519\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01641541976928711\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.050763049407955264\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0007893463897751644\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03515769226073753\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.010906587677006611\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010828186332702171\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03954558486938477\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005156299591064453\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007985268452449236\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0268393217468285\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.016918984570307657\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.051645046539301985\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0718947171325679\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14603152695312166\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03140442230224144\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0480140760498005\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.019513759918208234\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.06473278900146252\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022747086587524973\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05194446258544922\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0010567611694335937\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.002082130813598633\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005099476135219448\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0020350152831990274\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0038877029113820755\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0008157575439428911\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006555640083318577\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0014139153076219372\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00017248191833496094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: 2.5357353283415542\n",
      "[I 2025-07-03 14:40:08.999886] Trial 14 finished with value: 2.5357353283415542 and parameters: {'learning_rate': 1.1024795761328347e-05, 'n_steps': 5, 'gamma': 0.9686669858979843, 'ent_coef': 0.0001018149889190306}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 992552.48\n",
      "total_reward: -7447.52\n",
      "total_cost: 174.12\n",
      "total_trades: 32\n",
      "Sharpe: -0.926\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:40:16,544] Trial 15 finished with value: 0.0 and parameters: {'learning_rate': 0.008676319896370447, 'n_steps': 10, 'gamma': 0.9984662530566164, 'ent_coef': 9.261512971612688e-05}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: 0.0\n",
      "[I 2025-07-03 14:40:16.531017] Trial 15 finished with value: 0.0 and parameters: {'learning_rate': 0.008676319896370447, 'n_steps': 10, 'gamma': 0.9984662530566164, 'ent_coef': 9.261512971612688e-05}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1053246.34\n",
      "total_reward: 53246.34\n",
      "total_cost: 5957.79\n",
      "total_trades: 736\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:40:26,373] Trial 16 finished with value: 3.952179413433848 and parameters: {'learning_rate': 8.103906703103831e-05, 'n_steps': 5, 'gamma': 0.9809927490866305, 'ent_coef': 6.132609710587799e-07}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.00977536711501889\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01399476528854575\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.048995248196413745\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009603591079707258\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012575260101316963\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07114420416259673\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003087871240230743\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.049973559474176726\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.05482010314941872\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.034385263409418984\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0022115994659368883\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12972123947143555\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18055806546325331\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07717177903747652\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03364735836791806\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08444536585693714\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07030335552978795\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09870625953674317\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.033678364959720056\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.040441445465083235\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1984623260208173\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1564127189331106\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10059088786315407\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07460432479858864\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04572584457397461\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.008488597802736331\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0023846863494836725\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01320949533691164\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.011032881927490235\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.036445541210938244\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.020354700117488394\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.004042999877932016\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0003318241241504438\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.002783505706791766\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0013703332519507967\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.002171869766234886\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.011230437011714094\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005605161926266738\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.034394094189454334\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.010959026596066542\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.098670412495418\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.039686971813964196\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.048218017736810725\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.012815984954836313\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.049753212585451546\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.030415202429203782\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.045668134765629656\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.055593527145381086\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.005696764436340891\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.020543757781980095\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.009240656030271202\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01026410314636305\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01197226093140198\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.01423553562926827\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0007404945831280202\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00028284691772423684\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.021062114562990612\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0025444488143897617\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0003273303543101065\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.013869771873473656\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.01363669472350739\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006961512727360241\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02044802862548968\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.016978990325925408\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08197858688354027\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.034304491181951016\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013908842773432843\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06108390162964352\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006680765348812566\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0011038919067359529\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.023826187950139865\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02013442380371271\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00931196166991722\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005352815203857608\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0014316922607365997\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02754729644774925\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00045520691223209725\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11197310381775023\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04190580520629883\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003857042160036508\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.033828755760192876\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.024944988708500752\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.050267778225708756\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25633139761963397\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003335367736814078\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04774193797454937\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.055229071942134764\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0023422184753464537\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.030355638107296547\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.020823735459893942\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0017036428833031097\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02235791717529064\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11325137619018788\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.004794264129642397\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05610111862182385\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.16873953837433364\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.017770887756347657\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08025069728851086\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.16727879461975537\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14527109527587892\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.003953978498838842\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.249906463012693\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07023267340698512\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11491393226166256\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03643454421997303\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1318965775756864\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2860306442260742\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0384987158721895\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.29333395468749807\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.04692092910766369\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0562222303466755\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1806545306365937\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10204122528076405\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007408393554692157\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.10497691115264315\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.33046686828613747\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.034319981842045676\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14888014648742975\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31172799765624803\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1201181678039604\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.036329637145996095\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.49593737153472617\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18502801996765195\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13087772195892175\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04838875701904763\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1257000572875957\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2266362346405047\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0556510019348003\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1781070276855375\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08170724272918888\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.015599987136840356\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31275185745239725\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.029285588378901595\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12870317977904341\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1878287887573126\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.12715397933960193\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09136890487670898\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1068792765808059\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11683802917480934\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1619861468505813\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.29862030822753444\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07530162008209154\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11472294357300271\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4141391305404715\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1804585131835891\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2552685763549758\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.42812343494873495\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12146904074706837\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.19386014770508045\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02810397736511659\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.007401511166384444\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21362202087402113\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.27977663864135977\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13040406665649498\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3708932813598658\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0640514389038086\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18577000889129705\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18109592344665434\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4731363039855962\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.627277930297854\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.30465130385131345\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.21717624053955079\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5775912829589798\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5237286269378616\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03260823919067625\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24972853744508466\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03816904645842733\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.147701202514663\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9449762334228378\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.10965134973296663\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.19898078873901395\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5498883731918294\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.39689110702514885\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.28537935848693596\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.13085747726440897\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5497660267028841\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1922463493347168\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6597389623046853\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3041061830139137\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17308309238586808\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25580833990935936\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7802781791687012\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2786231263305643\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.04746288540954702\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09318559896240478\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4799528789062519\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24890981063842774\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22155416841125117\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20840312402038835\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.41718720830688255\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23200407214965674\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09302182942810469\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23056295089721682\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15718350250243676\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3451518347167992\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.024154463159176524\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.30218289886474375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25020691611937945\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07199907935180236\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4616457627868629\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02089091948241694\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.08526371520996327\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4512069998153718\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7753176832809463\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24862041298828555\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.40672616271972656\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09507080538939917\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6140930786300683\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7260192596435547\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18913791100158125\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5016417649841286\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.49683100467986663\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.20101033420411404\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0970359736633487\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8804538146972773\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3457677611328196\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5583537592712557\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.12289331913756905\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3510249150085496\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.005215986557013821\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3801756841674913\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17388315737762022\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14675222183992156\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.31131795425416203\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.044763673027034385\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14987605168152368\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2589622367477394\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14479603076173225\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3243215834487812\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.45389693437195383\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9673820887329058\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.25927579729309075\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4353963125610375\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.32316892204894687\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5949308480834938\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3633839745849604\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8036901799011161\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03673461448668968\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.1462772201538086\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4651924746185192\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2773113317871117\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5421693222046131\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.041827265014615846\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.28230153430176436\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14310703521117102\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.02573373908995418\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11399750380552141\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11399750380552141\n",
      "Current state shape: (13,)\n",
      "Total test reward: 3.952179413433848\n",
      "[I 2025-07-03 14:40:26.350169] Trial 16 finished with value: 3.952179413433848 and parameters: {'learning_rate': 8.103906703103831e-05, 'n_steps': 5, 'gamma': 0.9809927490866305, 'ent_coef': 6.132609710587799e-07}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999576.97\n",
      "total_reward: -423.03\n",
      "total_cost: 27.31\n",
      "total_trades: 4\n",
      "Sharpe: -0.819\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:40:35,906] Trial 17 finished with value: -0.010674913339235355 and parameters: {'learning_rate': 0.0010053435717285173, 'n_steps': 5, 'gamma': 0.9649553264982748, 'ent_coef': 1.1801223363654554e-05}. Best is trial 3 with value: 24.24192699010313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.00405914892120054\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0014733230590820313\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0005887166122440249\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006285807205201127\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.001214563659671694\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: -0.010674913339235355\n",
      "[I 2025-07-03 14:40:35.894802] Trial 17 finished with value: -0.010674913339235355 and parameters: {'learning_rate': 0.0010053435717285173, 'n_steps': 5, 'gamma': 0.9649553264982748, 'ent_coef': 1.1801223363654554e-05}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999643.70\n",
      "total_reward: -356.30\n",
      "total_cost: 216.47\n",
      "total_trades: 41\n",
      "Sharpe: -0.415\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:40:45,561] Trial 18 finished with value: 27.60640236133414 and parameters: {'learning_rate': 0.0006615388535469933, 'n_steps': 5, 'gamma': 0.9533340857791796, 'ent_coef': 7.314281110226074e-08}. Best is trial 18 with value: 27.60640236133414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.01150043190002907\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.02770465553284157\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09524111121367897\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.014940552444453352\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.022189920654299203\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13767072158813246\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.004390952091978397\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07078134719848167\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07179490231323289\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05366395538330544\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0035592304992722347\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.23634207611083985\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3099723944244441\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.14874239715576407\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.07493094970092644\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.24807417321777903\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2517929359436035\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.39148703327941475\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1833684959411621\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17312931777953636\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8770763719177224\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6346379299926804\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5076947723388672\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5609090519714403\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5349206071777386\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2107768098205561\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07478261057586642\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6017779364257818\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14591723865509268\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4927569784545922\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.39347172592163554\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2936420370483422\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0666818357849144\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.11532220352173318\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.13645532531738283\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7852723037719727\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3582322086914093\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.15659200306701243\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6621390600585961\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18714498376159464\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6488477952575662\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9286898425292922\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7643987850952079\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4392242160293623\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.811085344216926\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7644117335510208\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7308282466430683\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7976250045410125\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1530833876037621\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1241003014678952\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.34435592315674296\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.989465975291445\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7932580438232515\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6283057110839989\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.48481454086303716\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5951270901489305\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9115821768188384\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.2935246105957078\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4803905455016997\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7463928912841948\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2171466972351075\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6092452255584533\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.26604028182982004\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9357133789062501\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.45348923967590093\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.334089753450011\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.62511924913025\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.36399912197266243\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.879522435607924\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.18976993301392067\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.009307721557607875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6894699705505511\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6563285218810896\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5516199939208803\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9211865032776027\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.17654765106202103\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9061613695556764\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.006146486932365224\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.7250119902847336\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7554892860412598\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.05587562459565234\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6471022285461426\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6677364943695022\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0343496961975005\n",
      "Current state shape: (13,)\n",
      "Step reward: 4.91525386871337\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.045580290063470606\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1159132338546682\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1693721493530087\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1243341919922037\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.616575050354004\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.32796459197998046\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.40665264129638673\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.548003387451172\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07215766906738282\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6296863555908203\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.7316930770874024\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.18366947174072268\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7527793658386218\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6002531871520915\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2266096115112306\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.03280353546142578\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.862856674194336\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5537917889404343\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8964238793060417\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24311359134672678\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.91158837890625\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.8035279296875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.25577841796875\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.856015771484375\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.31480576171875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.41974101562500005\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.3510085449218752\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.71485751953125\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.059017236328125\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6886085449218751\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9937293945312502\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.20987050781254657\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9247280273437035\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.82978701171875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7804344726562035\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.22295961914067158\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.8725596191406253\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9881899658691371\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7414315924560652\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.31481586914062504\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.741106494140625\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3484509334930452\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.34176818748773075\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.098967895050021\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5041989591582912\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09840049743652345\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.1645784378051993\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.17054805755619892\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8839067063217052\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.26292746546017\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.757533704304509\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5211453971862793\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5671992381545715\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5768671330017504\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8397152770996327\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7122390411377186\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4067645751953125\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5510814758301015\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.9877696685790784\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.9250072326660622\n",
      "Current state shape: (13,)\n",
      "Step reward: -6.0223845031737815\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.0599180084228514\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6232197052001953\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0562007385253906\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.14434723205566408\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.03942073669433594\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0970773834228515\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3204379669189454\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5780663299560547\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.6882772186279298\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3218871490478516\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8868503051757813\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9082847050277749\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.55486739900969\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.1137832275390624\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.4649267456054689\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0379210021972656\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.5816791107177735\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.3189281219482423\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1445089996337658\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0445130310059292\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.15765261535639877\n",
      "Current state shape: (13,)\n",
      "Step reward: -4.460478094482468\n",
      "Current state shape: (13,)\n",
      "Step reward: -3.514491629028274\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.4070227854446508\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7751271283355775\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.0101643676757814\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.3729517669677735\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.005072073364258\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.4795498748779297\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.9444766204833985\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.7226056610107422\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.3517467193603516\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.024797607421875\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5649530456542969\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8474194580078125\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.706482797241211\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0051125152587892\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.1682131818069378\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.34052555181884675\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6683099746704102\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8867063522338867\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8275993347167969\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8210285186767579\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6945831298828127\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9852281570434571\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.39408721923828127\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9261110305786133\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.5977016448974609\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.2216764450073243\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.08539028167724609\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0312036514282228\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8604129791259766\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.24961013793945314\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.6945932388305665\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.07882957458496094\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.288984489440918\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.5369441986083985\n",
      "Current state shape: (13,)\n",
      "Step reward: -2.7652116775512696\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8735748291015626\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.359602928161621\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3152778625488281\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.101822090148926\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.3645435333251954\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.604282569885254\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.6946033477783204\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7011640548706055\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.702784156799363\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3152677536011674\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.7820026397705546\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0522706985473866\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.7362724304199453\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3748600006103516\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.118079948425293\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.013161849975632505\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.1575250625610818\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.5327213287353516\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.44064903259279675\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.8812980651855702\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.11847897134399973\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.39805759934845847\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.6781100563705433\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.3814611434936989\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.8484237670897973\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.1904195785522462\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.6241817474365234\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7234569549560548\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.2824918746948242\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.9470365524292226\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.6407597055054037\n",
      "Current state shape: (13,)\n",
      "Step reward: 1.0043370123291155\n",
      "Current state shape: (13,)\n",
      "Step reward: 2.1032696537780344\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.09565410711669829\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3470887168884045\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.0978833370971495\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.6895325411010766\n",
      "Current state shape: (13,)\n",
      "Step reward: -1.387715911865281\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.09865322113032453\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.7102849960327149\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.3583926727416925\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.06394711837766227\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2828079223632347\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.2828079223632347\n",
      "Current state shape: (13,)\n",
      "Total test reward: 27.60640236133414\n",
      "[I 2025-07-03 14:40:45.539513] Trial 18 finished with value: 27.60640236133414 and parameters: {'learning_rate': 0.0006615388535469933, 'n_steps': 5, 'gamma': 0.9533340857791796, 'ent_coef': 7.314281110226074e-08}\n",
      "Train df shape: (743, 18), index range: 0 to 742\n",
      "Test df shape: (249, 18), index range: 0 to 248\n",
      "Inside create_env: data shape (743, 18), index range 0 to 742\n",
      "Inside create_env: data shape (249, 18), index range 0 to 248\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "day: 742, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000794.58\n",
      "total_reward: 794.58\n",
      "total_cost: 385.75\n",
      "total_trades: 68\n",
      "Sharpe: 0.529\n",
      "=================================\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n",
      "state: [1000000.0, np.float64(74.63008117675781), 0, np.float64(0.2504165059637273), np.float64(51.398809784158985), np.float64(-34.20001240594045), np.float64(11.97406829413876), np.float64(75.38160601529208), np.float64(75.38160601529208), np.float64(79.16018485227742), np.float64(72.22578392824015), np.float64(17.969999313354492), np.float64(0.0)]\n",
      "np.array(state).shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 14:40:53,264] Trial 19 finished with value: 0.004537449334713165 and parameters: {'learning_rate': 0.0007292864376238639, 'n_steps': 10, 'gamma': 0.937209628283432, 'ent_coef': 2.320215004441568e-08}. Best is trial 18 with value: 27.60640236133414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.89999961853028), np.float64(29.95463800380079)]\n",
      "np.array(state).shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.002850649067689665\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.000416353685001377\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0023489133605966344\n",
      "Current state shape: (13,)\n",
      "Step reward: -0.0002457594085717574\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Step reward: 0.0\n",
      "Current state shape: (13,)\n",
      "Total test reward: 0.004537449334713165\n",
      "[I 2025-07-03 14:40:53.251574] Trial 19 finished with value: 0.004537449334713165 and parameters: {'learning_rate': 0.0007292864376238639, 'n_steps': 10, 'gamma': 0.937209628283432, 'ent_coef': 2.320215004441568e-08}\n",
      "Best parameters: {'learning_rate': 0.0006615388535469933, 'n_steps': 5, 'gamma': 0.9533340857791796, 'ent_coef': 7.314281110226074e-08}\n",
      "Best reward: 27.60640236133414\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from stable_baselines3 import A2C\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "\n",
    "#  Set up Optuna storage\n",
    "os.makedirs(\"optuna_logs_\", exist_ok=True)\n",
    "db_path = \"sqlite:///optuna_logs_/a2c_optuna_study.db\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_file.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter AAPL\n",
    "df = df[df['tic'] == 'AAPL'].sort_values(by='date')\n",
    "print(f\"Overall AAPL data range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Total AAPL rows: {len(df)}\")\n",
    "\n",
    "# Tech indicators\n",
    "tech_indicator_list = [\n",
    "    'macd', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma',\n",
    "    'boll_ub', 'boll_lb','vix', 'turbulence'\n",
    "]\n",
    "\n",
    "# Create stock trading environment\n",
    "def create_env(data):\n",
    "    data = data.reset_index(drop=True)\n",
    "    print(f\"Inside create_env: data shape {data.shape}, index range {data.index.min()} to {data.index.max()}\")\n",
    "\n",
    "    stock_dim = len(data.tic.unique())\n",
    "    state_space = 1 + 2 * stock_dim + len(tech_indicator_list) * stock_dim\n",
    "    action_space = stock_dim\n",
    "    num_stock_shares = [0] * stock_dim\n",
    "\n",
    "    return StockTradingEnv(\n",
    "        df=data,\n",
    "        stock_dim=stock_dim,\n",
    "        hmax=100,\n",
    "        initial_amount=1e6,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=[0.001],\n",
    "        sell_cost_pct=[0.001],\n",
    "        reward_scaling=1e-4,\n",
    "        state_space=state_space,\n",
    "        action_space=action_space,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        user_defined_feature=[]\n",
    "    )\n",
    "\n",
    "# Helper to serialize params to a hashable tuple\n",
    "def serialize_params(params):\n",
    "    return tuple(sorted(params.items()))\n",
    "\n",
    "# Set to track tried params during this run\n",
    "tried_params = set()\n",
    "\n",
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),\n",
    "        'n_steps': trial.suggest_categorical('n_steps', [5, 10, 20, 50]),\n",
    "        'gamma': trial.suggest_float('gamma', 0.9, 0.999),\n",
    "        'ent_coef': trial.suggest_float('ent_coef', 1e-8, 1e-2, log=True)\n",
    "    }\n",
    "\n",
    "    param_key = serialize_params(params)\n",
    "    if param_key in tried_params:\n",
    "        # Duplicate parameters found, prune this trial\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    tried_params.add(param_key)\n",
    "\n",
    "    learning_rate = params['learning_rate']\n",
    "    n_steps = params['n_steps']\n",
    "    gamma = params['gamma']\n",
    "    ent_coef = params['ent_coef']\n",
    "\n",
    "    # Manual date split\n",
    "    train_df = df[(df['date'] >= '2020-02-02') & (df['date'] <= '2022-12-31')].reset_index(drop=True)\n",
    "    test_df  = df[(df['date'] >= '2023-01-01') & (df['date'] <= '2023-12-28')].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Train df shape: {train_df.shape}, index range: {train_df.index.min()} to {train_df.index.max()}\")\n",
    "    print(f\"Test df shape: {test_df.shape}, index range: {test_df.index.min()} to {test_df.index.max()}\")\n",
    "\n",
    "    if train_df.empty or test_df.empty:\n",
    "        print(\"Warning: Train or test data is empty for these date ranges.\")\n",
    "        return -float('inf')\n",
    "\n",
    "    env_train = create_env(train_df)\n",
    "    env_test = create_env(test_df)\n",
    "\n",
    "    model = A2C(\n",
    "        \"MlpPolicy\",\n",
    "        env_train,\n",
    "        learning_rate=learning_rate,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        ent_coef=ent_coef,\n",
    "        verbose=0,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=10000)\n",
    "\n",
    "    # Evaluation\n",
    "    obs, _ = env_test.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env_test.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        total_reward += reward\n",
    "        print(f\"Step reward: {reward}\")\n",
    "        print(f\"Current state shape: {np.array(obs).shape}\")\n",
    "\n",
    "    print(f\"Total test reward: {total_reward}\")\n",
    "    print(f\"[I {datetime.datetime.now()}] Trial {trial.number} finished with value: {total_reward} and parameters: {trial.params}\")\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "# Run tuning with storage\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='a2c_hyperparam_tuning',\n",
    "    storage=db_path,\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Results\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best reward:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b294fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1148192/3641543642.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "2025-06-30 20:04:44,422\tINFO worker.py:1684 -- Calling ray.init() again after it has already been called.\n",
      "2025-06-30 20:04:44,423\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  total_reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_a2c_b3af7_00000</td><td style=\"text-align: right;\">    14.7737   </td></tr>\n",
       "<tr><td>train_a2c_b3af7_00001</td><td style=\"text-align: right;\">     2.61768  </td></tr>\n",
       "<tr><td>train_a2c_b3af7_00002</td><td style=\"text-align: right;\">     0.298049 </td></tr>\n",
       "<tr><td>train_a2c_b3af7_00003</td><td style=\"text-align: right;\">    -0.0091618</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 20:04:54,596\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/group3/ray_results/train_a2c_2025-06-30_20-04-44' in 0.0033s.\n",
      "2025-06-30 20:04:54,599\tINFO tune.py:1041 -- Total run time: 10.18 seconds (10.16 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:    {'learning_rate': 0.0051516766303610064, 'n_steps': 50, 'gamma': 0.9187677611590532, 'ent_coef': 8.349001727462869e-08, 'vf_coef': 0.6162179381220239, 'max_grad_norm': 2.231050842340027, 'gae_lambda': 0.9372004380248778}\n",
      "Best total reward:               14.7736697\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from ray import train as ray_train\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"/home/group3/processed_full.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['tic'] == 'AAPL'].sort_values(by='date')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure no NaN values\n",
    "tech_indicator_list = [\n",
    "    'macd', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma',\n",
    "    'boll_ub', 'boll_lb', 'turbulence'\n",
    "]\n",
    "\n",
    "# Check for missing indicators\n",
    "missing = [col for col in tech_indicator_list if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing technical indicators in dataset: {missing}\")\n",
    "\n",
    "# Fill or drop NaNs\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "def create_env(data):\n",
    "    data = data.copy().reset_index(drop=True)\n",
    "\n",
    "    # Ensure the DataFrame is not empty\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Provided DataFrame to create_env is empty.\")\n",
    "\n",
    "    stock_dim = len(data.tic.unique())\n",
    "    state_space = 1 + 2 * stock_dim + len(tech_indicator_list) * stock_dim\n",
    "    action_space = stock_dim\n",
    "    num_stock_shares = [0] * stock_dim\n",
    "\n",
    "    return StockTradingEnv(\n",
    "        df=data,\n",
    "        stock_dim=stock_dim,\n",
    "        hmax=100,\n",
    "        initial_amount=1e6,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=[0.001] * stock_dim,\n",
    "        sell_cost_pct=[0.001] * stock_dim,\n",
    "        reward_scaling=1e-4,\n",
    "        state_space=state_space,\n",
    "        action_space=action_space,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        user_defined_feature=[]\n",
    "    )\n",
    "\n",
    "\n",
    "class TuneReportCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % 1000 == 0 and len(self.model.ep_info_buffer) >= 10:\n",
    "            last_rewards = list(self.model.ep_info_buffer)[-10:]\n",
    "            mean_reward = np.mean([ep['r'] for ep in last_rewards if 'r' in ep])\n",
    "            ray_train.report({\"total_reward\": mean_reward, \"training_iteration\": self.num_timesteps})\n",
    "        return True\n",
    "\n",
    "\n",
    "def train_a2c(config):\n",
    "    import traceback\n",
    "    try:\n",
    "        # Data split with fixed date formatting\n",
    "        train_df = df[(df['date'] >= '2020-02-02') & (df['date'] <= '2022-12-31')].reset_index(drop=True)\n",
    "        test_df  = df[(df['date'] >= '2023-01-01') & (df['date'] <= '2023-12-28')].reset_index(drop=True)\n",
    "\n",
    "        env_train = create_env(train_df)\n",
    "        env_test  = create_env(test_df)\n",
    "\n",
    "        model = A2C(\n",
    "            \"MlpPolicy\",\n",
    "            env_train,\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            n_steps=config[\"n_steps\"],\n",
    "            gamma=config[\"gamma\"],\n",
    "            ent_coef=config[\"ent_coef\"],\n",
    "            vf_coef=config.get(\"vf_coef\", 0.5),\n",
    "            max_grad_norm=config.get(\"max_grad_norm\", 0.5),\n",
    "            gae_lambda=config.get(\"gae_lambda\", 0.95),\n",
    "            verbose=0,\n",
    "            device=\"cpu\"\n",
    "        )\n",
    "\n",
    "        model.learn(total_timesteps=10_000, callback=TuneReportCallback())\n",
    "\n",
    "        reset_out = env_test.reset()\n",
    "        obs = reset_out[0] if isinstance(reset_out, tuple) else reset_out\n",
    "\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            step_out = env_test.step(action)\n",
    "            if len(step_out) == 5:\n",
    "                obs, reward, terminated, truncated, info = step_out\n",
    "                done = terminated or truncated\n",
    "            else:\n",
    "                obs, reward, done, info = step_out\n",
    "            total_reward += reward\n",
    "\n",
    "        print(f\"[{datetime.datetime.now()}] Final test reward: {total_reward}\", flush=True)\n",
    "        ray_train.report({\"total_reward\": total_reward})\n",
    "\n",
    "    except Exception:\n",
    "        print(\"\\U0001F6A8 Exception in train_a2c:\\n\", traceback.format_exc(), flush=True)\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    pbt = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        perturbation_interval=1,\n",
    "        hyperparam_mutations={\n",
    "            \"learning_rate\": lambda: np.random.uniform(1e-5, 1e-2),\n",
    "            \"n_steps\": [5, 10, 20, 50],\n",
    "            \"gamma\": lambda: np.random.uniform(0.9, 0.999),\n",
    "            \"ent_coef\": lambda: 10 ** np.random.uniform(-8, -2),\n",
    "            \"vf_coef\": lambda: np.random.uniform(0.1, 1.0),\n",
    "            \"max_grad_norm\": lambda: np.random.uniform(0.3, 5.0),\n",
    "            \"gae_lambda\": lambda: np.random.uniform(0.8, 1.0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    analysis = tune.run(\n",
    "        train_a2c,\n",
    "        resources_per_trial={\"cpu\": 1},\n",
    "        config={\n",
    "            \"learning_rate\": tune.uniform(1e-5, 1e-2),\n",
    "            \"n_steps\": tune.choice([5, 10, 20, 50]),\n",
    "            \"gamma\": tune.uniform(0.9, 0.999),\n",
    "            \"ent_coef\": tune.loguniform(1e-8, 1e-2),\n",
    "            \"vf_coef\": tune.uniform(0.1, 1.0),\n",
    "            \"max_grad_norm\": tune.uniform(0.3, 5.0),\n",
    "            \"gae_lambda\": tune.uniform(0.8, 1.0),\n",
    "        },\n",
    "        num_samples=32,\n",
    "        scheduler=pbt,\n",
    "        stop={\"training_iteration\": 50},\n",
    "        reuse_actors=True,\n",
    "        metric=\"total_reward\",\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found were:   \", analysis.best_config)\n",
    "    print(\"Best total reward:              \", analysis.best_result[\"total_reward\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7272b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1193774/959832286.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "2025-07-01 18:32:59,711\tINFO worker.py:1684 -- Calling ray.init() again after it has already been called.\n",
      "2025-07-01 18:32:59,712\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  total_reward</th><th style=\"text-align: right;\">  train_reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_a2c_0d08e_00000</td><td style=\"text-align: right;\">   0.0162806  </td><td style=\"text-align: right;\">     3.71165  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00001</td><td style=\"text-align: right;\">   0.277092   </td><td style=\"text-align: right;\">     0.20742  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00002</td><td style=\"text-align: right;\">  30.7083     </td><td style=\"text-align: right;\">    56.1815   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00003</td><td style=\"text-align: right;\">   0.33654    </td><td style=\"text-align: right;\">    63.7323   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00004</td><td style=\"text-align: right;\">  -0.00289557 </td><td style=\"text-align: right;\">    13.5919   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00005</td><td style=\"text-align: right;\">  -0.0480388  </td><td style=\"text-align: right;\">     0.587349 </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00006</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">     4.28851  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00007</td><td style=\"text-align: right;\">  18.2259     </td><td style=\"text-align: right;\">    48.9923   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00008</td><td style=\"text-align: right;\">   2.01185    </td><td style=\"text-align: right;\">     2.37041  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00009</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">     6.18802  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00010</td><td style=\"text-align: right;\">  17.5378     </td><td style=\"text-align: right;\">     1.37987  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00011</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">     0.156804 </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00012</td><td style=\"text-align: right;\">   6.82085    </td><td style=\"text-align: right;\">    16.4719   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00013</td><td style=\"text-align: right;\">   0.0413154  </td><td style=\"text-align: right;\">     6.31106  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00014</td><td style=\"text-align: right;\">  30.7083     </td><td style=\"text-align: right;\">    42.0651   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00015</td><td style=\"text-align: right;\">  -0.000341971</td><td style=\"text-align: right;\">    11.7081   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00016</td><td style=\"text-align: right;\">  19.1563     </td><td style=\"text-align: right;\">    14.0099   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00017</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">    -0.0768195</td></tr>\n",
       "<tr><td>train_a2c_0d08e_00018</td><td style=\"text-align: right;\">   0.0187876  </td><td style=\"text-align: right;\">    14.7436   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00019</td><td style=\"text-align: right;\">  30.7083     </td><td style=\"text-align: right;\">    67.8405   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00020</td><td style=\"text-align: right;\">  -0.0194319  </td><td style=\"text-align: right;\">    -1.56842  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00021</td><td style=\"text-align: right;\">   0.00548618 </td><td style=\"text-align: right;\">    59.3854   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00022</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">    52.5643   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00023</td><td style=\"text-align: right;\">  29.9474     </td><td style=\"text-align: right;\">    18.3894   </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00024</td><td style=\"text-align: right;\">  -0.0390265  </td><td style=\"text-align: right;\">    19.764    </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00025</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">    -0.0227242</td></tr>\n",
       "<tr><td>train_a2c_0d08e_00026</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">    -0.825747 </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00027</td><td style=\"text-align: right;\">   0          </td><td style=\"text-align: right;\">     0.254467 </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00028</td><td style=\"text-align: right;\">   0.310968   </td><td style=\"text-align: right;\">     5.56813  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00029</td><td style=\"text-align: right;\">   0.0386023  </td><td style=\"text-align: right;\">     4.31814  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00030</td><td style=\"text-align: right;\">  30.2299     </td><td style=\"text-align: right;\">     9.03503  </td></tr>\n",
       "<tr><td>train_a2c_0d08e_00031</td><td style=\"text-align: right;\">  30.3815     </td><td style=\"text-align: right;\">    62.1053   </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 18:33:10,811\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00000. Skip exploit for Trial train_a2c_0d08e_00005\n",
      "2025-07-01 18:33:11,069\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00000. Skip exploit for Trial train_a2c_0d08e_00003\n",
      "2025-07-01 18:33:11,221\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00007. Skip exploit for Trial train_a2c_0d08e_00001\n",
      "2025-07-01 18:33:13,745\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00007. Skip exploit for Trial train_a2c_0d08e_00002\n",
      "2025-07-01 18:33:17,582\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00004. Skip exploit for Trial train_a2c_0d08e_00009\n",
      "2025-07-01 18:33:18,061\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00010. Skip exploit for Trial train_a2c_0d08e_00013\n",
      "2025-07-01 18:33:18,757\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00007. Skip exploit for Trial train_a2c_0d08e_00011\n",
      "2025-07-01 18:33:33,049\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00014. Skip exploit for Trial train_a2c_0d08e_00026\n",
      "2025-07-01 18:33:37,207\tINFO pbt.py:716 -- [pbt]: no checkpoint for trial train_a2c_0d08e_00007. Skip exploit for Trial train_a2c_0d08e_00028\n",
      "2025-07-01 18:34:10,247\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/group3/ray_results/train_a2c_2025-07-01_18-32-59' in 0.0131s.\n",
      "2025-07-01 18:34:10,254\tINFO tune.py:1041 -- Total run time: 70.54 seconds (70.51 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best hyperparameters found:\n",
      "  learning_rate: 0.007930200752995114\n",
      "  n_steps: 5\n",
      "  gamma: 0.9402488874458206\n",
      "  ent_coef: 0.0006815558675725959\n",
      "  vf_coef: 0.5573157709832984\n",
      "  max_grad_norm: 2.538836058793725\n",
      "  gae_lambda: 0.8367847301726301\n",
      "\n",
      " Best performance:\n",
      "  Test Reward (total_reward): 30.71\n",
      "  Train Reward (train_reward): 56.18\n",
      "\n",
      " Top 5 Trials:\n",
      "             total_reward  train_reward\n",
      "trial_id                               \n",
      "0d08e_00002     30.708335     56.181514\n",
      "0d08e_00014     30.708335     42.065106\n",
      "0d08e_00019     30.708335     67.840544\n",
      "0d08e_00031     30.381498     62.105299\n",
      "0d08e_00030     30.229944      9.035029\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from ray import train as ray_train\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"/home/group3/processed_full.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['tic'] == 'AAPL'].sort_values(by='date')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure no NaN values\n",
    "tech_indicator_list = [\n",
    "    'macd', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma',\n",
    "    'boll_ub', 'boll_lb', 'turbulence', 'sentiment_score', 'vix'\n",
    "]\n",
    "\n",
    "# Check for missing indicators\n",
    "missing = [col for col in tech_indicator_list if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing technical indicators in dataset: {missing}\")\n",
    "\n",
    "# Fill or drop NaNs\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "def create_env(data):\n",
    "    data = data.copy().reset_index(drop=True)\n",
    "\n",
    "    # Ensure the DataFrame is not empty\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Provided DataFrame to create_env is empty.\")\n",
    "\n",
    "    stock_dim = len(data.tic.unique())\n",
    "    state_space = 1 + 2 * stock_dim + len(tech_indicator_list) * stock_dim\n",
    "    action_space = stock_dim\n",
    "    num_stock_shares = [0] * stock_dim\n",
    "\n",
    "    return StockTradingEnv(\n",
    "        df=data,\n",
    "        stock_dim=stock_dim,\n",
    "        hmax=100,\n",
    "        initial_amount=1e6,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=[0.001] * stock_dim,\n",
    "        sell_cost_pct=[0.001] * stock_dim,\n",
    "        reward_scaling=1e-4,\n",
    "        state_space=state_space,\n",
    "        action_space=action_space,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        user_defined_feature=[]\n",
    "    )\n",
    "\n",
    "\n",
    "class TuneReportCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % 1000 == 0 and len(self.model.ep_info_buffer) >= 10:\n",
    "            last_rewards = list(self.model.ep_info_buffer)[-10:]\n",
    "            mean_reward = np.mean([ep['r'] for ep in last_rewards if 'r' in ep])\n",
    "            ray_train.report({\"total_reward\": mean_reward, \"training_iteration\": self.num_timesteps})\n",
    "        return True\n",
    "\n",
    "\n",
    "def train_a2c(config):\n",
    "    import traceback\n",
    "    try:\n",
    "        # Data split\n",
    "        train_df = df[(df['date'] >= '2020-02-02') & (df['date'] <= '2022-12-31')].reset_index(drop=True)\n",
    "        test_df  = df[(df['date'] >= '2023-01-01') & (df['date'] <= '2023-12-28')].reset_index(drop=True)\n",
    "\n",
    "        env_train = create_env(train_df)\n",
    "        env_test  = create_env(test_df)\n",
    "\n",
    "        model = A2C(\n",
    "            \"MlpPolicy\",\n",
    "            env_train,\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            n_steps=config[\"n_steps\"],\n",
    "            gamma=config[\"gamma\"],\n",
    "            ent_coef=config[\"ent_coef\"],\n",
    "            vf_coef=config.get(\"vf_coef\", 0.5),\n",
    "            max_grad_norm=config.get(\"max_grad_norm\", 0.5),\n",
    "            gae_lambda=config.get(\"gae_lambda\", 0.95),\n",
    "            verbose=0,\n",
    "            device=\"cpu\"\n",
    "        )\n",
    "\n",
    "        model.learn(total_timesteps=10_000)\n",
    "\n",
    "        # Calculate training reward (average over buffer)\n",
    "        train_reward = 0\n",
    "        if len(model.ep_info_buffer) > 0:\n",
    "            train_reward = np.mean([ep['r'] for ep in model.ep_info_buffer if 'r' in ep])\n",
    "\n",
    "        # Evaluate on test set\n",
    "        reset_out = env_test.reset()\n",
    "        obs = reset_out[0] if isinstance(reset_out, tuple) else reset_out\n",
    "\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            step_out = env_test.step(action)\n",
    "            if len(step_out) == 5:\n",
    "                obs, reward, terminated, truncated, info = step_out\n",
    "                done = terminated or truncated\n",
    "            else:\n",
    "                obs, reward, done, info = step_out\n",
    "            total_reward += reward\n",
    "\n",
    "        print(f\"[{datetime.datetime.now()}] Final test reward: {total_reward} | Train reward: {train_reward}\", flush=True)\n",
    "\n",
    "        # Report both\n",
    "        ray_train.report({\n",
    "            \"total_reward\": total_reward,  # used for optimization\n",
    "            \"train_reward\": train_reward   # optional info\n",
    "        })\n",
    "\n",
    "    except Exception:\n",
    "        print(\" Exception in train_a2c:\\n\", traceback.format_exc(), flush=True)\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    pbt = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        perturbation_interval=1,\n",
    "        hyperparam_mutations={\n",
    "            \"learning_rate\": lambda: np.random.uniform(1e-5, 1e-2),\n",
    "            \"n_steps\": [5, 10, 20, 50],\n",
    "            \"gamma\": lambda: np.random.uniform(0.9, 0.999),\n",
    "            \"ent_coef\": lambda: 10 ** np.random.uniform(-8, -2),\n",
    "            \"vf_coef\": lambda: np.random.uniform(0.1, 1.0),\n",
    "            \"max_grad_norm\": lambda: np.random.uniform(0.3, 5.0),\n",
    "            \"gae_lambda\": lambda: np.random.uniform(0.8, 1.0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    analysis = tune.run(\n",
    "        train_a2c,\n",
    "        resources_per_trial={\"cpu\": 1},\n",
    "        config={\n",
    "            \"learning_rate\": tune.uniform(1e-5, 1e-2),\n",
    "            \"n_steps\": tune.choice([5, 10, 20, 50]),\n",
    "            \"gamma\": tune.uniform(0.9, 0.999),\n",
    "            \"ent_coef\": tune.loguniform(1e-8, 1e-2),\n",
    "            \"vf_coef\": tune.uniform(0.1, 1.0),\n",
    "            \"max_grad_norm\": tune.uniform(0.3, 5.0),\n",
    "            \"gae_lambda\": tune.uniform(0.8, 1.0),\n",
    "        },\n",
    "        num_samples=32,\n",
    "        scheduler=pbt,\n",
    "        stop={\"training_iteration\": 50},\n",
    "        reuse_actors=True,\n",
    "        metric=\"total_reward\",  # still optimizing for test reward\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    best_config = analysis.best_config\n",
    "    best_result = analysis.best_result\n",
    "\n",
    "    print(\"\\n Best hyperparameters found:\")\n",
    "    for k, v in best_config.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    print(\"\\n Best performance:\")\n",
    "    print(f\"  Test Reward (total_reward): {best_result['total_reward']:.2f}\")\n",
    "    if 'train_reward' in best_result:\n",
    "        print(f\"  Train Reward (train_reward): {best_result['train_reward']:.2f}\")\n",
    "\n",
    "    # Optional: view all results sorted by test reward\n",
    "    print(\"\\n Top 5 Trials:\")\n",
    "    df = analysis.results_df.sort_values(\"total_reward\", ascending=False)\n",
    "    print(df[['total_reward', 'train_reward']].dropna().head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe49817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1531171/1537352480.py:40: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "2025-07-06 16:22:47,162\tINFO worker.py:1684 -- Calling ray.init() again after it has already been called.\n",
      "2025-07-06 16:22:47,163\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "/home/group3/venv/lib/python3.12/site-packages/ray/tune/tune.py:730: UserWarning: Consider boosting PBT performance by enabling `reuse_actors` as well as implementing `reset_config` for Trainable.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>should_checkpoint  </th><th style=\"text-align: right;\">  val_reward</th><th style=\"text-align: right;\">  val_sharpe</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_a2c_b075e_00000</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "<tr><td>train_a2c_b075e_00001</td><td>True               </td><td style=\"text-align: right;\">   -1.39597 </td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00002</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "<tr><td>train_a2c_b075e_00003</td><td>True               </td><td style=\"text-align: right;\">   -0.153556</td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00004</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "<tr><td>train_a2c_b075e_00005</td><td>True               </td><td style=\"text-align: right;\">   -1.39597 </td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00006</td><td>True               </td><td style=\"text-align: right;\">   -0.80966 </td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00007</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "<tr><td>train_a2c_b075e_00008</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "<tr><td>train_a2c_b075e_00009</td><td>True               </td><td style=\"text-align: right;\">   -1.39597 </td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00010</td><td>True               </td><td style=\"text-align: right;\">   -0.697983</td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00011</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "<tr><td>train_a2c_b075e_00012</td><td>True               </td><td style=\"text-align: right;\">   -1.39597 </td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00013</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "<tr><td>train_a2c_b075e_00014</td><td>True               </td><td style=\"text-align: right;\">   -1.39597 </td><td style=\"text-align: right;\">    -8.73622</td></tr>\n",
       "<tr><td>train_a2c_b075e_00015</td><td>True               </td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">     0      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 16:22:58,759\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/group3/ray_results/train_a2c_2025-07-06_16-22-47' in 0.0081s.\n",
      "2025-07-06 16:22:58,764\tINFO tune.py:1041 -- Total run time: 11.60 seconds (11.58 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Searching for best checkpoint...\n",
      "Trial: b075e_00000 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00000_0_ent_coef=0.0000,gae_lambda=0.9514,gamma=0.9860,learning_rate=0.0038,max_grad_norm=2.9738,n_steps=20,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00001 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00001_1_ent_coef=0.0000,gae_lambda=0.8681,gamma=0.9655,learning_rate=0.0038,max_grad_norm=3.1544,n_steps=10,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00002 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00002_2_ent_coef=0.0001,gae_lambda=0.9775,gamma=0.9934,learning_rate=0.0059,max_grad_norm=2.5490,n_steps=5,vf_coef_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00003 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00003_3_ent_coef=0.0003,gae_lambda=0.9588,gamma=0.9507,learning_rate=0.0038,max_grad_norm=4.5524,n_steps=20,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00004 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00004_4_ent_coef=0.0061,gae_lambda=0.8643,gamma=0.9676,learning_rate=0.0037,max_grad_norm=0.8196,n_steps=50,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00005 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00005_5_ent_coef=0.0000,gae_lambda=0.9651,gamma=0.9329,learning_rate=0.0081,max_grad_norm=4.1725,n_steps=10,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00006 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00006_6_ent_coef=0.0000,gae_lambda=0.9817,gamma=0.9594,learning_rate=0.0012,max_grad_norm=1.1662,n_steps=5,vf_coef_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00007 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00007_7_ent_coef=0.0015,gae_lambda=0.9385,gamma=0.9016,learning_rate=0.0083,max_grad_norm=4.1245,n_steps=20,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00008 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00008_8_ent_coef=0.0000,gae_lambda=0.9923,gamma=0.9845,learning_rate=0.0054,max_grad_norm=3.1837,n_steps=10,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00009 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00009_9_ent_coef=0.0004,gae_lambda=0.8167,gamma=0.9645,learning_rate=0.0005,max_grad_norm=3.6685,n_steps=50,vf_coe_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00010 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00010_10_ent_coef=0.0000,gae_lambda=0.9392,gamma=0.9560,learning_rate=0.0012,max_grad_norm=4.4010,n_steps=10,vf_co_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00011 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00011_11_ent_coef=0.0000,gae_lambda=0.9978,gamma=0.9810,learning_rate=0.0078,max_grad_norm=4.1815,n_steps=50,vf_co_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00012 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00012_12_ent_coef=0.0000,gae_lambda=0.8359,gamma=0.9281,learning_rate=0.0037,max_grad_norm=4.7921,n_steps=50,vf_co_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00013 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00013_13_ent_coef=0.0031,gae_lambda=0.9409,gamma=0.9092,learning_rate=0.0099,max_grad_norm=3.3438,n_steps=10,vf_co_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00014 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00014_14_ent_coef=0.0000,gae_lambda=0.9787,gamma=0.9851,learning_rate=0.0079,max_grad_norm=3.2011,n_steps=20,vf_co_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      "Trial: b075e_00015 at /tmp/ray/session_2025-07-06_16-18-54_147038_1531171/artifacts/2025-07-06_16-22-47/train_a2c_2025-07-06_16-22-47/driver_artifacts/train_a2c_b075e_00015_15_ent_coef=0.0000,gae_lambda=0.9100,gamma=0.9247,learning_rate=0.0079,max_grad_norm=3.4073,n_steps=50,vf_co_2025-07-06_16-22-47\n",
      "  Found model.zip files: []\n",
      " Using checkpoint from: /tmp/checkpoint_tmp_411d1bc59cf54276a7859074cc62ec31/model.zip\n",
      " Running model on test environment...\n",
      "state: [1000000.0, np.float64(123.4706039428711), 0, np.float64(-4.648599978133859), np.float64(39.011473477232165), np.float64(-130.96362055980674), np.float64(35.95635234416873), np.float64(138.29393107096354), np.float64(140.56728642781576), np.float64(147.86027471441827), np.float64(121.09183405023016), np.float64(22.899999618530277), np.float64(29.95463800380079), np.float64(-0.4482758620689655)]\n",
      "np.array(state).shape: (14,)\n",
      "\n",
      "day: 249, episode: 1\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.41\n",
      "state: [np.float64(902589.2702420965), np.float64(192.17269897460935), np.int64(527), np.float64(1.827838483282335), np.float64(57.09262120258462), np.float64(31.224968602159294), np.float64(8.33348999976474), np.float64(191.39605102539065), np.float64(183.4469113667806), np.float64(197.5935125287889), np.float64(187.94217014943376), np.float64(12.470000267028809), np.float64(2.091830598183032), np.float64(0.0)]\n",
      "np.array(state).shape: (14,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import traceback\n",
    "import uuid\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray import train as ray_train  # still needed for checkpoint_dir\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configurable parameters ---\n",
    "TOTAL_TRAIN_TIMESTEPS = 10_000\n",
    "REPORT_FREQ = 500\n",
    "NUM_CV_FOLDS = 3\n",
    "USE_GPU = False\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"/home/group3/processed_full.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['tic'] == 'AAPL'].sort_values(by='date')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "tech_indicator_list = [\n",
    "    'macd', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma',\n",
    "    'boll_ub', 'boll_lb','vix', 'turbulence','sentiment_score'\n",
    "]\n",
    "\n",
    "missing = [col for col in tech_indicator_list if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing technical indicators in dataset: {missing}\")\n",
    "\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "def create_env(data):\n",
    "    data = data.copy().reset_index(drop=True)\n",
    "\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Provided DataFrame to create_env is empty.\")\n",
    "\n",
    "    stock_dim = len(data.tic.unique())\n",
    "    state_space = 1 + 2 * stock_dim + len(tech_indicator_list) * stock_dim\n",
    "    action_space = stock_dim\n",
    "    num_stock_shares = [0] * stock_dim\n",
    "\n",
    "    return StockTradingEnv(\n",
    "        df=data,\n",
    "        stock_dim=stock_dim,\n",
    "        hmax=100,\n",
    "        initial_amount=1e6,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=[0.001] * stock_dim,\n",
    "        sell_cost_pct=[0.001] * stock_dim,\n",
    "        reward_scaling=1e-4,\n",
    "        state_space=state_space,\n",
    "        action_space=action_space,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        user_defined_feature=[]\n",
    "    )\n",
    "\n",
    "class TuneReportCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, report_freq=REPORT_FREQ):\n",
    "        super().__init__(verbose)\n",
    "        self.report_freq = report_freq\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.report_freq == 0 and len(self.model.ep_info_buffer) > 0:\n",
    "            last_rewards = list(self.model.ep_info_buffer)[-10:]\n",
    "            rewards = [ep['r'] for ep in last_rewards if 'r' in ep]\n",
    "            if len(rewards) > 0:\n",
    "                mean_reward = np.mean(rewards)\n",
    "                ray_train.report({\"val_reward\": mean_reward, \"training_iteration\": self.num_timesteps})\n",
    "        return True\n",
    "\n",
    "def sharpe_ratio(rewards):\n",
    "    rewards = np.array(rewards)\n",
    "    mean_ret = np.mean(rewards)\n",
    "    std_ret = np.std(rewards)\n",
    "    if std_ret == 0:\n",
    "        return 0\n",
    "    return (mean_ret / std_ret) * np.sqrt(252)\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def cross_validate(model):\n",
    "    \"\"\"\n",
    "    Runs cross-validation on validation splits of data.\n",
    "    Evaluates the model in each fold environment and returns average\n",
    "    validation reward and Sharpe ratio over folds.\n",
    "    \"\"\"\n",
    "    val_start_date = '2022-07-01'\n",
    "    val_end_date = '2022-12-31'\n",
    "    \n",
    "    # Filter validation data for folds (we'll split it by time)\n",
    "    val_df = df[(df['date'] >= val_start_date) & (df['date'] <= val_end_date)].reset_index(drop=True)\n",
    "    \n",
    "    # Use TimeSeriesSplit for time-based folding\n",
    "    tscv = TimeSeriesSplit(n_splits=NUM_CV_FOLDS)\n",
    "    \n",
    "    fold_rewards = []\n",
    "    \n",
    "    for fold_idx, (train_index, val_index) in enumerate(tscv.split(val_df)):\n",
    "        fold_val_df = val_df.iloc[val_index].reset_index(drop=True)\n",
    "        \n",
    "        if fold_val_df.empty:\n",
    "            print(f\"Warning: Fold {fold_idx} validation data is empty. Skipping this fold.\")\n",
    "            continue\n",
    "        \n",
    "        # Create env for validation fold\n",
    "        val_env = create_env(fold_val_df)\n",
    "        \n",
    "        obs = val_env.reset()\n",
    "        obs = obs[0] if isinstance(obs, tuple) else obs\n",
    "        \n",
    "        done = False\n",
    "        rewards = []\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            step_out = val_env.step(action)\n",
    "            if len(step_out) == 5:\n",
    "                obs, reward, terminated, truncated, info = step_out\n",
    "                done = terminated or truncated\n",
    "            else:\n",
    "                obs, reward, done, info = step_out\n",
    "                \n",
    "            rewards.append(reward)\n",
    "        \n",
    "        fold_rewards.append(np.sum(rewards))\n",
    "    \n",
    "    # Compute average val reward and Sharpe ratio across folds\n",
    "    if fold_rewards:\n",
    "        avg_val_reward = np.mean(fold_rewards)\n",
    "        val_sharpe = sharpe_ratio(fold_rewards)\n",
    "    else:\n",
    "        avg_val_reward = 0\n",
    "        val_sharpe = 0\n",
    "    \n",
    "    print(f\"Cross-validation results: avg_reward={avg_val_reward:.4f}, sharpe={val_sharpe:.4f}\")\n",
    "    return avg_val_reward, val_sharpe\n",
    "\n",
    "\n",
    "def train_a2c(config):\n",
    "    try:\n",
    "        train_df = df[(df['date'] >= '2020-02-02') & (df['date'] <= '2022-06-30')].reset_index(drop=True)\n",
    "        env_train = create_env(train_df)\n",
    "        device = \"cuda\" if USE_GPU else \"cpu\"\n",
    "\n",
    "        model = A2C(\n",
    "            \"MlpPolicy\",\n",
    "            env_train,\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            n_steps=config[\"n_steps\"],\n",
    "            gamma=config[\"gamma\"],\n",
    "            ent_coef=config[\"ent_coef\"],\n",
    "            vf_coef=config.get(\"vf_coef\", 0.5),\n",
    "            max_grad_norm=config.get(\"max_grad_norm\", 0.5),\n",
    "            gae_lambda=config.get(\"gae_lambda\", 0.95),\n",
    "            verbose=0,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        callback = TuneReportCallback(report_freq=REPORT_FREQ)\n",
    "\n",
    "        trial_id = str(uuid.uuid4())[:8]\n",
    "        base_trial_dir = f\"manual_trial_{trial_id}\"\n",
    "        os.makedirs(base_trial_dir, exist_ok=True)\n",
    "\n",
    "        total_steps = 0\n",
    "        while total_steps < TOTAL_TRAIN_TIMESTEPS:\n",
    "            model.learn(total_timesteps=REPORT_FREQ, reset_num_timesteps=False, callback=callback)\n",
    "            total_steps += REPORT_FREQ\n",
    "\n",
    "            # Run cross-validation here periodically\n",
    "            val_reward, val_sharpe = cross_validate(model)\n",
    "\n",
    "            # Save checkpoint\n",
    "            checkpoint_dir = os.path.join(base_trial_dir, f\"checkpoint_{total_steps}\")\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, \"model.zip\")\n",
    "            model.save(checkpoint_path)\n",
    "            print(f\"Checkpoint saved at step {total_steps} to {checkpoint_path}\", flush=True)\n",
    "\n",
    "            # Report real validation metrics to Tune\n",
    "            ray_train.report(\n",
    "                {\n",
    "                    \"val_reward\": val_reward,\n",
    "                    \"val_sharpe\": val_sharpe,\n",
    "                    \"training_iteration\": total_steps\n",
    "                },\n",
    "                checkpoint=ray_train.Checkpoint.from_directory(checkpoint_dir)\n",
    "            )\n",
    "\n",
    "        # Final cross-validation after training ends\n",
    "        val_reward, val_sharpe = cross_validate(model)\n",
    "\n",
    "        # Compute final training reward (optional)\n",
    "        train_reward = 0\n",
    "        if len(model.ep_info_buffer) > 0:\n",
    "            rewards = [ep['r'] for ep in model.ep_info_buffer if 'r' in ep]\n",
    "            train_reward = np.mean(rewards) if rewards else 0\n",
    "\n",
    "        tune.report(\n",
    "            val_reward=val_reward,\n",
    "            val_sharpe=val_sharpe,\n",
    "            train_reward=train_reward,\n",
    "        )\n",
    "\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    pbt = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        perturbation_interval=1,\n",
    "        hyperparam_mutations={\n",
    "            \"learning_rate\": lambda: np.random.uniform(1e-5, 1e-2),\n",
    "            \"n_steps\": [5, 10, 20, 50],\n",
    "            \"gamma\": lambda: np.random.uniform(0.9, 0.999),\n",
    "            \"ent_coef\": lambda: 10 ** np.random.uniform(-8, -2),\n",
    "            \"vf_coef\": lambda: np.random.uniform(0.1, 1.0),\n",
    "            \"max_grad_norm\": lambda: np.random.uniform(0.3, 5.0),\n",
    "            \"gae_lambda\": lambda: np.random.uniform(0.8, 1.0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    analysis = tune.run(\n",
    "        train_a2c,\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": 1 if USE_GPU else 0},\n",
    "        config={\n",
    "            \"learning_rate\": tune.uniform(1e-5, 1e-2),\n",
    "            \"n_steps\": tune.choice([5, 10, 20, 50]),\n",
    "            \"gamma\": tune.uniform(0.9, 0.999),\n",
    "            \"ent_coef\": tune.loguniform(1e-8, 1e-2),\n",
    "            \"vf_coef\": tune.uniform(0.1, 1.0),\n",
    "            \"max_grad_norm\": tune.uniform(0.3, 5.0),\n",
    "            \"gae_lambda\": tune.uniform(0.8, 1.0),\n",
    "        },\n",
    "        num_samples=16,\n",
    "        scheduler=pbt,\n",
    "        stop={\"training_iteration\": 50},\n",
    "        metric=\"val_reward\",\n",
    "        mode=\"max\",\n",
    "        keep_checkpoints_num=2,\n",
    "        checkpoint_score_attr=\"val_reward\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\U0001F50D Searching for best checkpoint...\")\n",
    "\n",
    "    for trial in analysis.trials:\n",
    "        print(f\"Trial: {trial.trial_id} at {trial.local_path}\")\n",
    "        import glob\n",
    "        model_files = glob.glob(os.path.join(trial.local_path, \"**\", \"model.zip\"), recursive=True)\n",
    "        print(f\"  Found model.zip files: {model_files}\")\n",
    "\n",
    "    best_trial = analysis.get_best_trial(\"val_reward\", mode=\"max\")\n",
    "    best_checkpoint = analysis.get_best_checkpoint(best_trial, metric=\"val_reward\", mode=\"max\")\n",
    "\n",
    "    if best_checkpoint is None:\n",
    "        import glob\n",
    "        trial_logdir = best_trial.local_path\n",
    "        model_files = glob.glob(os.path.join(trial_logdir, \"**\", \"model.zip\"), recursive=True)\n",
    "        print(\"Fallback: found model files:\", model_files)\n",
    "        if model_files:\n",
    "            model_path = model_files[0]\n",
    "        else:\n",
    "            raise FileNotFoundError(\" No valid checkpoint or model.zip found!\")\n",
    "    else:\n",
    "        checkpoint_dir = best_checkpoint.to_directory()\n",
    "        model_path = os.path.join(checkpoint_dir, \"model.zip\")\n",
    "\n",
    "\n",
    "    print(f\" Using checkpoint from: {model_path}\")\n",
    "\n",
    "    test_df = df[(df['date'] >= '2023-01-01') & (df['date'] <= '2023-12-28')].reset_index(drop=True)\n",
    "    env_test = create_env(test_df)\n",
    "    device = \"cuda\" if USE_GPU else \"cpu\"\n",
    "    best_model = A2C.load(model_path, env=env_test, device=device)\n",
    "\n",
    "    print(\"\\U0001F680 Running model on test environment...\")\n",
    "\n",
    "# Capture starting total asset from env\n",
    "if hasattr(env_test, 'total_asset'):\n",
    "    begin_total_asset = env_test.total_asset\n",
    "elif hasattr(env_test, 'portfolio_value'):\n",
    "    begin_total_asset = env_test.portfolio_value\n",
    "else:\n",
    "    begin_total_asset = 1e6  # fallback default\n",
    "\n",
    "obs = env_test.reset()\n",
    "obs = obs[0] if isinstance(obs, tuple) else obs\n",
    "\n",
    "done = False\n",
    "step_rewards = []\n",
    "total_reward = 0\n",
    "portfolio_values = [begin_total_asset]\n",
    "step_count = 0\n",
    "\n",
    "while not done:\n",
    "    action, _ = best_model.predict(obs)\n",
    "    step_out = env_test.step(action)\n",
    "\n",
    "    if len(step_out) == 5:\n",
    "        obs, reward, terminated, truncated, info = step_out\n",
    "        done = terminated or truncated\n",
    "    else:\n",
    "        obs, reward, done, info = step_out\n",
    "\n",
    "    step_rewards.append(reward)\n",
    "    total_reward += reward\n",
    "    step_count += 1\n",
    "\n",
    "    # Track portfolio value each step if available\n",
    "    current_asset = None\n",
    "    if info and 'total_asset' in info:\n",
    "        current_asset = info['total_asset']\n",
    "    elif hasattr(env_test, 'total_asset'):\n",
    "        current_asset = env_test.total_asset\n",
    "    elif hasattr(env_test, 'portfolio_value'):\n",
    "        current_asset = env_test.portfolio_value\n",
    "    \n",
    "    if current_asset is not None:\n",
    "        portfolio_values.append(current_asset)\n",
    "    else:\n",
    "        portfolio_values.append(portfolio_values[-1])  # repeat last if no update\n",
    "\n",
    "# Final total asset\n",
    "end_total_asset = portfolio_values[-1]\n",
    "\n",
    "print(f\"\\nday: {step_count}, episode: 1\")\n",
    "print(f\"begin_total_asset: {begin_total_asset:.2f}\")\n",
    "print(f\"end_total_asset: {end_total_asset:.2f}\")\n",
    "print(f\"total_reward: {total_reward:.2f}\")\n",
    "\n",
    "print(f\"state: {obs}\")\n",
    "print(f\"np.array(state).shape: {np.array(obs).shape}\")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.cumsum(step_rewards), label=\"Cumulative Reward\", color=\"green\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Cumulative Reward\")\n",
    "plt.title(\"Test-Time Reward Trajectory (Best Model)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(portfolio_values, label=\"Portfolio Value\", color=\"blue\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.title(\"Test-Time Portfolio Value Trajectory\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_reward_and_portfolio_trajectory.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
