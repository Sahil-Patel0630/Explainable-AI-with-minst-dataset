{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6918d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_high_vix_by_ticker(df):\n",
    "    \"\"\"\n",
    "    Calculate the 'high_vix' feature for each ticker.\n",
    "    VIX is compared to its 20-day rolling mean for each ticker.\n",
    "    Assumes 'vix', 'tic', and 'date' columns exist in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Sort the data by ticker and date (ensure proper chronological order within each ticker)\n",
    "    df = df.sort_values(by=['tic', 'date'])\n",
    "\n",
    "    # Function to calculate high_vix for each group (per ticker)\n",
    "    def calc_high_vix_for_ticker(group):\n",
    "        # Calculate the 20-day rolling mean of VIX for each ticker\n",
    "        group['vix_rolling_mean_20'] = group['vix'].rolling(window=20).mean()\n",
    "\n",
    "        # Create 'high_vix' (1 if current VIX > 98% of rolling mean, else 0)\n",
    "        group['high_vix'] = (group['vix'] > 0.98 * group['vix_rolling_mean_20']).astype(int)\n",
    "\n",
    "        return group\n",
    "\n",
    "    # Apply the function for each ticker (grouped by 'tic')\n",
    "    df = df.groupby('tic').apply(calc_high_vix_for_ticker)\n",
    "\n",
    "    # Optional: Remove rows where rolling mean is NaN (first 19 rows for each ticker)\n",
    "    df = df.dropna(subset=['vix_rolling_mean_20'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "483612bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicators used: ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "Number of indicators: 8\n",
      "Stock Dimension: 1, State Space (calculated): 11\n",
      "state: [1000000, np.float64(2.7309935092926025), 0, np.float64(0.0), np.float64(2.951623720329186), np.float64(2.6256222303696664), np.float64(100.0), np.float64(66.66666666666667), np.float64(100.0), np.float64(2.7309935092926025), np.float64(2.7309935092926025), np.float64(0.0), np.float64(2.951623720329186), np.float64(2.6256222303696664), np.float64(100.0), np.float64(66.66666666666667), np.float64(100.0), np.float64(2.7309935092926025), np.float64(2.7309935092926025)]\n",
      "np.array(state).shape: (19,)\n",
      "âœ… Observation shape from environment: (19,)\n",
      "state: [1000000, np.float64(2.7309935092926025), 0, np.float64(0.0), np.float64(2.951623720329186), np.float64(2.6256222303696664), np.float64(100.0), np.float64(66.66666666666667), np.float64(100.0), np.float64(2.7309935092926025), np.float64(2.7309935092926025), np.float64(0.0), np.float64(2.951623720329186), np.float64(2.6256222303696664), np.float64(100.0), np.float64(66.66666666666667), np.float64(100.0), np.float64(2.7309935092926025), np.float64(2.7309935092926025)]\n",
      "np.array(state).shape: (19,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (19,) into shape (11,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Observation shape from environment:\u001b[39m\u001b[33m\"\u001b[39m, obs.shape)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Convert to Stable-Baselines compatible env\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m env_train, _ = \u001b[43me_train_gym\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_sb_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Stable-Baselines environment type:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(env_train))\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Initialize DRL Agent\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/finrl/meta/env_stock_trading/env_stocktrading.py:566\u001b[39m, in \u001b[36mStockTradingEnv.get_sb_env\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_sb_env\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    565\u001b[39m     e = DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     obs = \u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e, obs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:79\u001b[39m, in \u001b[36mDummyVecEnv.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m     maybe_options = {\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m     78\u001b[39m     obs, \u001b[38;5;28mself\u001b[39m.reset_infos[env_idx] = \u001b[38;5;28mself\u001b[39m.envs[env_idx].reset(seed=\u001b[38;5;28mself\u001b[39m._seeds[env_idx], **maybe_options)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mself\u001b[39m._reset_seeds()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:109\u001b[39m, in \u001b[36mDummyVecEnv._save_obs\u001b[39m\u001b[34m(self, env_idx, obs)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keys:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuf_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m = obs\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m         \u001b[38;5;28mself\u001b[39m.buf_obs[key][env_idx] = obs[key]\n",
      "\u001b[31mValueError\u001b[39m: could not broadcast input array from shape (19,) into shape (11,)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from stable_baselines3.common.logger import configure\n",
    "import numpy as np\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "\n",
    "# Create necessary directories\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/group3/train.csv')\n",
    "\n",
    "# Filter for one stock (AAPL)\n",
    "train = train[train['tic'] == 'AAPL']\n",
    "\n",
    "# Debug: Check indicators and dimensions\n",
    "print(\"Indicators used:\", INDICATORS)\n",
    "print(\"Number of indicators:\", len(INDICATORS))\n",
    "\n",
    "stock_dimension = 1  # only AAPL\n",
    "state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space (calculated): {state_space}\")\n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,  # required in newer FinRL versions\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "# Create training environment\n",
    "train = train.reset_index(drop=True)\n",
    "e_train_gym = StockTradingEnv(df=train, user_defined_feature=INDICATORS, **env_kwargs)\n",
    "\n",
    "# Optional: validate observation shape\n",
    "obs,_ = e_train_gym.reset()\n",
    "obs = np.array(obs)\n",
    "print(\"âœ… Observation shape from environment:\", obs.shape)\n",
    "\n",
    "# Convert to Stable-Baselines compatible env\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(\"âœ… Stable-Baselines environment type:\", type(env_train))\n",
    "\n",
    "# Initialize DRL Agent\n",
    "agent = DRLAgent(env=env_train)\n",
    "\n",
    "# Choose algorithms to train\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True\n",
    "\n",
    "# Train A2C\n",
    "if if_using_a2c:\n",
    "    model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "    # Set up logger\n",
    "    tmp_path = RESULTS_DIR + '/a2c'\n",
    "    new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    model_a2c.set_logger(new_logger_a2c)\n",
    "\n",
    "    trained_a2c = agent.train_model(\n",
    "        model=model_a2c,\n",
    "        tb_log_name='a2c',\n",
    "        total_timesteps=50000\n",
    "    )\n",
    "\n",
    "    trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\")\n",
    "    print(\"âœ… A2C model training complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119f019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/group3/nltk_data...\n",
      "/home/group3/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/group3/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“° News 1: Share market update: Most active stocks of the day in terms of traded value. The NSE Nifty index closed 140.5 points  down  at 24971.9\n",
      "ðŸ“ˆ Detected Regime: volatile\n",
      "\n",
      "ðŸ“° News 2: Unilever to acquire men's personal care brand Dr Squatch. Unilever has been divesting and selectively acquiring personal care brands in recent years.\n",
      "ðŸ“ˆ Detected Regime: volatile\n",
      "\n",
      "ðŸ“° News 3: ORG Partners LLC Has $69,000 Stock Holdings in Howmet Aerospace Inc. (NYSE:HWM). ORG Partners LLC lifted its position in shares of Howmet Aerospace Inc. (NYSE:HWM â€“ Free Report) by 31.5% during the 1st quarter, Holdings Channel reports. The firm owned 526 shares of the companyâ€™s stock after purchasing an additional 126 shares during the qâ€¦\n",
      "ðŸ“ˆ Detected Regime: bullish\n",
      "\n",
      "ðŸ“° News 4: Stonegate Investment Group LLC Acquires Shares of 684 Synopsys, Inc. (NASDAQ:SNPS). Stonegate Investment Group LLC acquired a new stake in Synopsys, Inc. (NASDAQ:SNPS â€“ Free Report) during the first quarter, Holdings Channel.com reports. The fund acquired 684 shares of the semiconductor companyâ€™s stock, valued at approximately $293,000. A nuâ€¦\n",
      "ðŸ“ˆ Detected Regime: neutral\n",
      "\n",
      "ðŸ“° News 5: 3,004 Shares in Vanguard Extended Market ETF (NYSEARCA:VXF) Bought by Advisor Resource Council. Advisor Resource Council purchased a new position in Vanguard Extended Market ETF (NYSEARCA:VXF â€“ Free Report) during the 1st quarter, according to the company in its most recent 13F filing with the Securities and Exchange Commission (SEC). The fund purchasedâ€¦\n",
      "ðŸ“ˆ Detected Regime: bullish\n"
     ]
    }
   ],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Replace with your actual API key\n",
    "newsapi = NewsApiClient(api_key='YOUR_NEWSAPI_KEY')\n",
    "def fetch_market_news(query=\"stock market\", language=\"en\", page_size=5):\n",
    "    articles = newsapi.get_everything(\n",
    "        q=query,\n",
    "        language=language,\n",
    "        sort_by='publishedAt',\n",
    "        page_size=page_size\n",
    "    )\n",
    "    headlines = [article['title'] + \". \" + article['description'] for article in articles['articles']]\n",
    "    return headlines\n",
    "from transformers import pipeline\n",
    "nltk.download('vader_lexicon')\n",
    "newsapi = NewsApiClient(api_key='db0eb7201950435b993447c710308800')\n",
    "\n",
    "# Load zero-shot classification model\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "def detect_market_regime(news_summary):\n",
    "    labels = [\"bullish\", \"bearish\", \"volatile\", \"neutral\"]\n",
    "    result = classifier(news_summary, candidate_labels=labels)\n",
    "    return result[\"labels\"][0]  # Highest score\n",
    "headlines = fetch_market_news()\n",
    "\n",
    "for i, news in enumerate(headlines):\n",
    "    regime = detect_market_regime(news)\n",
    "    print(f\"\\nðŸ“° News {i+1}: {news}\")\n",
    "    print(f\"ðŸ“ˆ Detected Regime: {regime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ae6b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 11\n",
      "state: [1000000, np.float64(2.7309935092926025), 0, np.float64(0.0), np.float64(2.951623720329186), np.float64(2.6256222303696664), np.float64(100.0), np.float64(66.66666666666667), np.float64(100.0), np.float64(2.7309935092926025), np.float64(2.7309935092926025), np.float64(0.0), np.float64(2.951623720329186), np.float64(2.6256222303696664), np.float64(100.0), np.float64(66.66666666666667), np.float64(100.0), np.float64(2.7309935092926025), np.float64(2.7309935092926025)]\n",
      "np.array(state).shape: (19,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (19,) into shape (11,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m train = train.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     37\u001b[39m e_train_gym = StockTradingEnv(df = train,user_defined_feature=INDICATORS,**env_kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m env_train, _ = \u001b[43me_train_gym\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_sb_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(env_train))\n\u001b[32m     42\u001b[39m agent = DRLAgent(env = env_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/finrl/meta/env_stock_trading/env_stocktrading.py:566\u001b[39m, in \u001b[36mStockTradingEnv.get_sb_env\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_sb_env\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    565\u001b[39m     e = DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     obs = \u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e, obs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:79\u001b[39m, in \u001b[36mDummyVecEnv.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m     maybe_options = {\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m     78\u001b[39m     obs, \u001b[38;5;28mself\u001b[39m.reset_infos[env_idx] = \u001b[38;5;28mself\u001b[39m.envs[env_idx].reset(seed=\u001b[38;5;28mself\u001b[39m._seeds[env_idx], **maybe_options)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mself\u001b[39m._reset_seeds()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:109\u001b[39m, in \u001b[36mDummyVecEnv._save_obs\u001b[39m\u001b[34m(self, env_idx, obs)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keys:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuf_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m = obs\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m         \u001b[38;5;28mself\u001b[39m.buf_obs[key][env_idx] = obs[key]\n",
      "\u001b[31mValueError\u001b[39m: could not broadcast input array from shape (19,) into shape (11,)"
     ]
    }
   ],
   "source": [
    "\n",
    "#Train Model\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])\n",
    "train = pd.read_csv('/home/group3/train.csv')\n",
    "# If you are not using the data generated from part 1 of this tutorial, make sure \n",
    "# it has the columns and index in the form that could be make into the environment. \n",
    "# Then you can comment and skip the following two lines.\n",
    "train = train[train['tic'] == 'AAPL']\n",
    "\n",
    "stock_dimension = 1\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "train = train.reset_index(drop=True)\n",
    "e_train_gym = StockTradingEnv(df = train,user_defined_feature=INDICATORS,**env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "\n",
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True\n",
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)\n",
    "\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=200000) if if_using_ppo else None\n",
    "\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)\n",
    "\n",
    "def process_df_for_mvo(df):\n",
    "  return df.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "\n",
    "!https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios/notebook\n",
    "\n",
    "def StockReturnsComputing(StockPrice, Rows, Columns): \n",
    "  import numpy as np \n",
    "  StockReturn = np.zeros([Rows-1, Columns]) \n",
    "  for j in range(Columns):        # j: Assets \n",
    "    for i in range(Rows-1):     # i: Daily Prices \n",
    "      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100 \n",
    "      \n",
    "  return StockReturn\n",
    "\n",
    "StockData = process_df_for_mvo(train)\n",
    "TradeData = process_df_for_mvo(trade)\n",
    "\n",
    "TradeData.to_numpy()\n",
    "\n",
    "#compute asset returns\n",
    "arStockPrices = np.asarray(StockData)\n",
    "[Rows, Cols]=arStockPrices.shape\n",
    "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "#compute mean returns and variance covariance matrix of returns\n",
    "meanReturns = np.mean(arReturns, axis = 0)\n",
    "covReturns = np.cov(arReturns, rowvar=False)\n",
    " \n",
    "#set precision for printing results\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "#display mean returns and variance-covariance matrix of returns\n",
    "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "print('Variance-Covariance matrix of returns\\n', covReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "%matplotlib inline\n",
    "train = pd.read_csv('train_data.csv')\n",
    "trade = pd.read_csv('trade_data.csv')\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True\n",
    "\n",
    "\n",
    "trained_ppo = PPO.load(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n",
    "\n",
    "\n",
    "\n",
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4}\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)\n",
    "def process_df_for_mvo(df):\n",
    "  return df.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "StockData = process_df_for_mvo(train)\n",
    "TradeData = process_df_for_mvo(trade)\n",
    "TradeData.to_numpy()\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "raw_weights_mean = ef_mean.max_sharpe()\n",
    "cleaned_weights_mean = ef_mean.clean_weights()\n",
    "# Wenn die Reihenfolge wichtig ist\n",
    "asset_keys = list(cleaned_weights_mean.keys())\n",
    "mvo_weights = np.array([1000000 * cleaned_weights_mean[asset] for asset in asset_keys])\n",
    "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "Initial_Portfolio\n",
    "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_result_ppo = (\n",
    "    df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "    if if_using_ppo\n",
    "    else None)\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"ppo\": df_result_ppo[\"account_value\"] if if_using_ppo else None,\n",
    "    })\n",
    "print(result)\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('apple_news_30_days_daily.csv')\n",
    "\n",
    "# Drop the 'url' column\n",
    "df = df.drop(columns=['url'])\n",
    "\n",
    "# Save the result back to CSV (overwrite or new file)\n",
    "df.to_csv('your_file_no_url.csv', index=False)\n",
    "\n",
    "print(\"Removed 'url' column and saved the new file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv('your_file_no_url.csv')\n",
    "\n",
    "# Initialize sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function to convert model output to a sentiment score\n",
    "def get_sentiment_score(text):\n",
    "    result = sentiment_pipeline(text)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    # Convert to numeric score: positive = +score, negative = -score\n",
    "    sentiment = score if label == 'POSITIVE' else -score\n",
    "    return round(sentiment, 5)\n",
    "\n",
    "# Apply to your title column\n",
    "df['sentiment_score'] = df['title'].astype(str).apply(get_sentiment_score)\n",
    "\n",
    "# Save results\n",
    "df.to_csv('your_file_with_sentiment.csv', index=False)\n",
    "\n",
    "print(df[['date','title', 'sentiment_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = '3037f06ec44841cab9703c8de7b5ac0d'\n",
    "\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "\n",
    "\n",
    "all_records = []\n",
    "\n",
    "# Loop through each day\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    next_date = current_date + timedelta(days=1)\n",
    "\n",
    "    url = (\n",
    "        'https://newsapi.org/v2/everything?'\n",
    "        f'q=Apple&'\n",
    "        f'from={current_date.strftime(\"%Y-%m-%d\")}&'\n",
    "        f'to={next_date.strftime(\"%Y-%m-%d\")}&'\n",
    "        'sortBy=publishedAt&'\n",
    "        'language=en&'\n",
    "        'pageSize=100&'\n",
    "        f'apiKey={API_KEY}'\n",
    "    )\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['status'] == 'ok':\n",
    "        articles = data['articles']\n",
    "        for article in articles:\n",
    "            all_records.append({\n",
    "                'date': article['publishedAt'],\n",
    "                'title': article['title'],\n",
    "                'url': article['url']\n",
    "            })\n",
    "        print(f\"Fetched {len(articles)} articles for {current_date.strftime('%Y-%m-%d')}\")\n",
    "    else:\n",
    "        print(f\"Error fetching data for {current_date.strftime('%Y-%m-%d')}: {data.get('message')}\")\n",
    "\n",
    "    current_date = next_date\n",
    "\n",
    "    # Be polite to API server, avoid rate limits\n",
    "    time.sleep(1)  \n",
    "\n",
    "# Save all data to CSV\n",
    "df = pd.DataFrame(all_records)\n",
    "df.to_csv('apple_news_30_days_daily.csv', index=False)\n",
    "print(f\"Saved total {len(df)} articles to apple_news_30_days_daily.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47065c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = '3037f06ec44841cab9703c8de7b5ac0d'\n",
    "\n",
    "end_date = datetime.today().replace(minute=0, second=0, microsecond=0)\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "all_records = []\n",
    "\n",
    "current_hour = start_date\n",
    "while current_hour < end_date:\n",
    "    next_hour = current_hour + timedelta(hours=1)\n",
    "    \n",
    "    url = (\n",
    "        'https://newsapi.org/v2/everything?'\n",
    "        f'q=Apple&'\n",
    "        f'from={current_hour.isoformat()}&'\n",
    "        f'to={next_hour.isoformat()}&'\n",
    "        'sortBy=publishedAt&'\n",
    "        'language=en&'\n",
    "        'pageSize=100&'\n",
    "        f'apiKey={API_KEY}'\n",
    "    )\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['status'] == 'ok':\n",
    "        articles = data['articles'][:1]  # Keep only first 4 articles per hour\n",
    "        for article in articles:\n",
    "            all_records.append({\n",
    "                'date': article['publishedAt'],\n",
    "                'title': article['title'],\n",
    "                'url': article['url']\n",
    "            })\n",
    "        print(f\"Fetched {len(articles)} articles for hour starting {current_hour}\")\n",
    "    else:\n",
    "        print(f\"Error fetching data for hour {current_hour}: {data.get('message')}\")\n",
    "    \n",
    "    current_hour = next_hour\n",
    "    time.sleep(1)  # avoid rate limits\n",
    "\n",
    "df = pd.DataFrame(all_records)\n",
    "df.to_csv('apple_news_4per_hour.csv', index=False)\n",
    "print(f\"Saved total {len(df)} articles to apple_news_4per_hour.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec35f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original data\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "# Filter only Apple (AAPL) data\n",
    "df_apple = df[df['tic'] == 'AAPL'].copy()\n",
    "\n",
    "# Reset index (optional but recommended)\n",
    "df_apple.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to new CSV file\n",
    "df_apple.to_csv(\"apple_stock_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ccb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('apple_stock_data.csv')\n",
    "\n",
    "# Feature engineering\n",
    "df['daily_return'] = df['close'].pct_change()\n",
    "df.to_csv('apple_stock_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0463495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volatility'] = df['daily_return'].rolling(window=10).std()\n",
    "df.to_csv('apple_stock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cebc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv('apple_stock_data.csv')  # Replace with your actual file name\n",
    "\n",
    "# Step 2: Define columns to scale\n",
    "scaled_columns = [\n",
    "    'close', 'high', 'low', 'open', 'volume',\n",
    "    'macd', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma', 'vix', 'turbulence'\n",
    "]\n",
    "\n",
    "# Step 3: Initialize the scaler and fit_transform\n",
    "scaler = MinMaxScaler()\n",
    "scaled_values = scaler.fit_transform(df[scaled_columns])\n",
    "\n",
    "# Step 4: Add new columns to df with '_scaled' suffix\n",
    "for i, col in enumerate(scaled_columns):\n",
    "    df[f'{col}_scaled'] = scaled_values[:, i]\n",
    "\n",
    "# Step 5: Save the updated dataframe to a new CSV file\n",
    "df.to_csv('apple_stock_scaled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
